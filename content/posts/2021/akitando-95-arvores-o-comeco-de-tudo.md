---
title: "[Akitando] #95 - √Årvores: O Come√ßo de TUDO | Estruturas de Dados e Algoritmos"
date: "2021-04-06T13:30:00.000Z"
tags: ["big o", "akitando", "√°rvore", "tree", "bst", "avl", "red black tree", "rbtree", "estrutura de dados", "ci√™ncia da computa√ß√£o"]
years: "2021"
---

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/9GdesxWtOgs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>DESCRI√á√ÉO</h2>
<p>Este √© o final da minha Trilogia de Estruturas de Dados e Algoritmos e finalmente vou conseguir falar sobre o mais importante na mat√©ria: √°rvores! Vamos de BSTs a AVLs, passando por Red Black Trees e muito mais! Se voc√™ nunca estudou sobre isso, ou n√£o tinha entendido quando estudou, esta √© sua chance!</p>
<p>Conte√∫do:</p>
<ul>
  <li>00:00 - Intro</li>
  <li>02:27 - Distribui√ß√£o Gaussiana</li>
  <li>05:53 - Hashing</li>
  <li>09:43 - Todo mundo erra</li>
  <li>10:18 - Recapitulando</li>
  <li>12:34 - Pilhas e Filas</li>
  <li>12:57 - Grafos</li>
  <li>13:25 - Entendendo Redes</li>
  <li>15:05 - Entendendo √Årvores</li>
  <li>16:34 - Heap/Mem√≥ria</li>
  <li>18:21 - Construindo √Årvores</li>
  <li>19:31 - Vantagem da Parti√ß√£o (log)</li>
  <li>20:18 - √Årvore de Procura Bin√°ria</li>
  <li>22:24 - Visualizando Inser√ß√£o na √Årvore</li>
  <li>26:19 - Imprimindo a √Årvore Ordenada</li>
  <li>30:24 - Procura Bin√°ria</li>
  <li>32:01 - Complexidade de Recursos</li>
  <li>34:52 - Pior Caso</li>
  <li>35:47 - Red Black Trees</li>
  <li>38:33 - Cor e Rota√ß√£o</li>
  <li>42:52 - AVL Trees</li>
  <li>44:51 - Red Black no Mundo Real</li>
  <li>47:06 - B-Tree e B+ Tree</li>
  <li>48:47 - Bancos de Dados</li>
  <li>52:46 - Intui√ß√£o em Algoritmos</li>
  <li>54:13 - Por que estudar tudo isso?</li>
  <li>57:04 - Conclus√£o</li>
</ul>
<p>Meus V√≠deos Mencionados:</p>
<ul>
  <li>Monetizar? Bloquear ADs? O que Fazer? (https://www.youtube.com/watch?v=dOe9X6Q_-nU)</li>
  <li>Entendendo Conceitos B√°sicos de CRIPTOGRAFIA | Parte 1/2 (https://www.youtube.com/watch?v=CcU5Kc_FN_4)</li>
  <li>O Guia +Hardcore de Introdu√ß√£o √† COMPUTA√á√ÉO (https://www.youtube.com/watch?v=8G80nuEyDN4)</li>
  <li>O Computador de Turing e Von Neumann | Por que calculadoras n√£o s√£o computadores? (https://www.youtube.com/watch?v=G4MvFT8TGII)</li>
  <li>Turing Complete, Emuladores e o Chip ARM M1 (https://www.youtube.com/watch?v=kz3649U2sJY)</li>
  <li>Qual a REAL diferen√ßa entre Arquivos Bin√°rio e Texto?? ü§î (https://www.youtube.com/watch?v=oSCVb4Ts-G4)</li>
  <li>Hello World Como Voc√™ Nunca Viu! | Entendendo C (https://www.youtube.com/watch?v=Gp2m8ZuXoPg)</li>
  <li>O que vem DEPOIS do Hello World | Consertando meu C (https://www.youtube.com/watch?v=YyWMN_0g3BQ)</li>
</ul>
<p>Links:</p>
<ul>
  <li>Red-black Trees (rbtree) in Linux (https://www.kernel.org/doc/Documentation/rbtree.txt)</li>
  <li>Red-black Trees Animated (https://www.cs.usfca.edu/~galles/visualization/RedBlack.html)</li>
</ul>
<p></p>
<p></p>
<h2>SCRIPT</h2>
<p>Ol√° pessoal, Fabio Akita</p>
<p>No final eu acabei me empolgando no assunto de algoritmos e estruturas de dados. Eu n√£o queria continuar porque d√° bastante trabalho fazer esse tipo de epis√≥dio, mas j√° que cheguei at√© aqui, me senti na obriga√ß√£o falar da estrutura de dados que eu considero a mais importante da mat√©ria: √°rvores ou trees.</p>
<p>Os v√≠deos acabaram trazendo muita gente nova que acho que n√£o entendeu a proposta do canal. Eu n√£o t√¥ fazendo um substituto pra cursos oficiais de faculdades, e eu nem tenho inten√ß√µes de parecer que seja. S√≥ t√¥ discutindo assuntos que acho que s√£o importantes que iniciantes procurem estudar por conta pr√≥pria. E pra isso eles precisam pelo menos saber que esses assuntos existem e porque s√£o importantes.</p>
<p>Pra quem n√£o sabe, o canal n√£o tem fins lucrativos, eu n√£o tenho patreons, nem patroc√≠nios de nenhum tipo, nem vendo nada. E tudo que √© arrecadado com ads eu fa√ßo doa√ß√£o de 200%, quer dizer, eu pego o que arrecado e dobro do meu bolso pra outros projetos de educa√ß√£o sem fins lucrativos. Vejam meu video acima explicando e n√£o esque√ßam de mandar mais sugest√µes de projetos pro e-mail contato @ codeminer42.com.</p>
<p>Como eu fa√ßo os v√≠deos nas minhas horas vagas e como desde o fim do ano passado meu volume de trabalho aumentou drasticamente, tem sobrado bem menos tempo pra me dedicar. Infelizmente n√£o √© porque t√¥ jogando muito videogame. Meu pobre PS5 t√° pegando p√≥ desde que comprei. E eu sou meio retardado das id√©ias e decidi justo fazer videos de 1 hora de dura√ß√£o, trabalhosos de editar, e obviamente cometi erros pra l√° e pra c√°. Desculpem por isso, mas lembrem que eu relato os principais nas erratas na descri√ß√£o e at√© mesmo no video seguinte. Por outro lado acho bacana que voc√™s est√£o prestando aten√ß√£o e notando esses erros.</p>
<p>E s√≥ pra variar, o comecinho do epis√≥dio de hoje vai ser pra eu falar das erratas do epis√≥dio anterior. Apesar de pra alguns parecer coisa pequena, √© importante eu explicar o correto, porque se voc√™ entender completamente esta miniss√©rie de 3 epis√≥dios, talvez comece a enxergar programa√ß√£o e c√≥digo de uma forma diferente. E mais do que isso: que cometer erros faz parte do processo. Ent√£o vamos l√°!</p>
<p>(...)</p>
<p>Um erro besta, mas importante, √© quando eu falo sobre a fun√ß√£o de hashing pro nosso exemplo de Hashtable. Sou o primeiro a dizer que as pessoas n√£o devem achar que tudo √© uma distribui√ß√£o gaussiana ou normal no mundo, porque n√£o s√£o. E eu mesmo cometi o erro de fazer isso. Vamos entender rapidamente porque isso √© importante e aproveitar pra fazer umas tangentes.</p>
<p>Eu n√£o vou explicar estat√≠stica porque eu n√£o me acho a pessoa mais adequada. Mas todo mundo j√° deve ter visto a distribui√ß√£o gaussiana ou normal. Todo tipo de evento independente pode ser gaussiano, por exemplo a altura m√©dia da popula√ß√£o. Faz de conta que se medirmos a altura de 100 pessoas, 80 v√£o estar nos 1 metro e sessenta, 12 v√£o estar perto de 1 metro e meio ou 1 metro e oitenta, e 8 entre 1 metro e quarenta e 1 metro e noventa. Se colocar isso num gr√°fico, mesmo medindo poucas pessoas, a gente come√ßa a ver o tal formato de sino ou bell shape, que caracteriza uma distribui√ß√£o normal.</p>
<p>A m√©dia √© onde costuma estar a maioria das medi√ß√µes, no meio. E quanto mais pra direita ou pra esquerda vai indo, as medi√ß√µes caem r√°pido. Essas dist√¢ncias a gente chama de sigmas. Se n√£o me engano, 65 porcento das medi√ß√µes v√£o estar em sigma 1, 95 porcento em sigma 2, e 99 ponto sete porcento em sigma tr√™s. Quem estudou coisas como processos de controle de qualidade conhece Six Sigma, ou sigma 6 que √© o famoso 99 ponto 99966 ou 3.4 defeitos por milh√£o.</p>
<p>Quando a gente fala 99.7% parece muito bom, porque nas nossas concep√ß√µes mais casuais, parece "perto de 100 porcento o suficiente", mas n√£o √©. Um contrato de SLA Sigma 3 de 99.7% significa 1 dia inteiro fora do ar num ano, por exemplo. Em uma ind√∫stria que produz milh√µes de itens por m√™s, significa 3 MIL defeitos por milh√£o de itens, por m√™s. Infelizmente, perfei√ß√£o, ou seja, zero defeitos √© quase imposs√≠vel no mundo real por per√≠odos prolongados de tempo. Eventualmente vai ter erros humanos, falhas mec√¢nicas. Six Sigma costuma ser a meta.</p>
<p>A √∫ltima coisa a se lembrar sobre distribui√ß√µes normais e m√©dias √© que elas s√≥ valem pra eventos independentes entre si. Quando voc√™ mensura coisas onde um n√£o afeta o outro, como jogar dados, pe√ßas fabricadas em massa, altura de uma popula√ß√£o. Mas um lugar onde todo mundo usa errado √© sal√°rios, porque o sal√°rio de um influencia o dos demais, n√£o √© um evento independente. √â um n√∫mero din√¢mico que varia por diversos fatores. Outras distribui√ß√µes estat√≠sticas v√£o se encaixar melhor como a Lei de Pot√™ncia ou Power Law, mas n√£o a gaussiana.</p>
<p>Enfim, essa tangente n√£o tem nada a ver com a minha errata, foi s√≥ algumas coisas que eu j√° queria compartilhar mesmo. Mas a errata √© que na explica√ß√£o sobre fun√ß√µes de hashing eu disse que o ideal seria uma fun√ß√£o que conseguisse devolver n√∫meros que caracterizam uma distribui√ß√£o gaussiana. Mas t√° errado, pois significa que na m√©dia ele ia devolver o mesmo valor, com alguns n√∫meros diferentes pr√≥ximos da m√©dia. Por exemplo, se fosse uma fun√ß√£o que devolve n√∫meros entre 1 e 10, ele poderia s√≥ ficar devolvendo o n√∫mero 5 por exemplo, que √© exatamente o oposto do que a gente quer.</p>
<p>Na verdade a distribui√ß√£o pra esse tipo de fun√ß√£o deve ser uniforme onde, a√≠ sim na m√©dia, ele devolve a mesma quantidade pra cada n√∫mero do range. E por isso minha confus√£o antes. No exemplo, se for uma fun√ß√£o que devolve n√∫meros de 1 a 10, e eu rodar essa fun√ß√£o cinquenta vezes, cada n√∫mero de 1 a 10 deveria aparecer na m√©dia 5 vezes, e assim balancear o uso do meu hashtable.</p>
<p>E mesmo assim n√£o deveria devolver cinco n√∫meros 1s, depois cinco n√∫meros 2s etc de forma f√°cil de prever, determin√≠stico, e a√≠ eu disse que deveria ser o mais pr√≥ximo de aleat√≥rio quanto poss√≠vel, se mantendo numa distribui√ß√£o uniforme. E eu sei que isso que eu acabei de falar, por si s√≥ √© assunto pra outro epis√≥dio, ent√£o pesquisem sobre n√∫meros pseudo-aleat√≥rios pra mais detalhes depois.</p>
<p>Continuando, eu usei o exemplo de fun√ß√£o de hashing djb2 e disse que n√£o √© necessariamente a melhor, mas n√£o t√° correto tamb√©m, na realidade a djb2 √© uma boa fun√ß√£o se voc√™ n√£o souber nenhuma outra. Como disse antes, o importante √© os resultados ca√≠rem o mais perto poss√≠vel de uma distribui√ß√£o uniforme e evitar colis√µes, ou seja, evitar devolver muito do mesmo resultado.</p>
<p>Dentre as fun√ß√µes de hashing mais conhecidas, um exemplo did√°tico √© o Lose Lose, um dos piores, muita colis√£o. Tem o Super Fast Hash, que como o nome diz, √© r√°pido, mas tamb√©m muita colis√£o. E tem o CRC32 que √© bom mas precisa de um lookup table de 1 kilobyte, ent√£o consome mais recursos que outros algoritmos, o que pode fazer diferen√ßa num ambiente limitado, como embarcado, mas √© bom pra todo o resto. N√£o tenho certeza de cabe√ßa, mas acho que √© usado em coisas como protocolos de rede, por exemplo.</p>
<p>O que eu venho explicando desde os epis√≥dios sobre Turing como tudo s√£o n√∫meros. Endere√ßos de mem√≥ria s√£o n√∫meros. Strings √© uma cadeia de bytes, tudo √© um numeroz√£o bin√°rio. E hashing √© uma forma de conseguir n√∫meros menores que representam um n√∫mero maior, como Strings. Ent√£o um texto da wikipedia √© um lingui√ß√£o de bits gigantes, um numeroz√£o enorme. E com hashing podemos etiquetar esse text√£o com um n√∫mero menor. No caso de um SHA-256 da vida, seria com uma etiqueta num√©rica de 256 bits. √â como um n√∫mero de s√©rie de um item. O ideal √© ser um n√∫mero √∫nico, mas n√£o √© garantia e por isso temos colis√µes onde dois itens diferentes, dois text√µes diferentes de wikipedia podem chegar no mesmo hash.</p>
<p>Quem j√° programa poderia pensar, mas porque n√£o usamos coisas como SHA-512? Eles s√£o usados pra seguran√ßa, n√£o s√£o melhores? Eles tem mais ou menos a mesma fun√ß√£o, devolver um n√∫mero que representa uma cadeia de bits, um String, como a chave do nosso hash. E esse n√∫mero costuma ser o mais √∫nico quanto poss√≠vel. Nunca vai ser 100% sempre √∫nico, mas quanto maior o valor do resultado, estatisticamente menores as chances disso acontecer.</p>
<p>Por√©m a categoria de fun√ß√µes de hashing como SHA-512 foram desenhados pra ter caracter√≠sticas de seguran√ßa, se usados em conjunto com coisas como salts, como eu expliquei no epis√≥dio de criptografia. S√£o mais avan√ßados e consomem mais recursos e mais processamento pra gerar esse n√∫mero. Portanto, n√£o s√£o necessariamente eficientes como geradores de chaves num hashtable se n√£o h√° requerimentos de seguran√ßa junto.</p>
<p>Em particular o SHA-512 √© r√°pido em m√°quinas de 64-bits porque as fun√ß√µes de c√°lculo vem implementado em hardware no CPU hoje em dia. De qualquer forma n√£o quer dizer que n√£o poderia ser usado, s√≥ que n√£o vai ser o mais eficiente pra hashtables gen√©ricos. E voltando pra errata, eu falei no video que o c√°lculo do djb2 faz bitwise shift de 5 bits pra esquerda, que √© um c√°lculo r√°pido e √© equivalente a multiplicar por 3 em decimal. O certo √© multiplicar por 32.</p>
<p>Eu ainda cometi dois erros sobre complexidade. O primeiro foi quando falei que NP √© tempo n√£o polinomial, mas o correto, que at√© falo depois no v√≠deo, √© que NP √© Non Deterministic Polynomial Time ou Tempo polinomial n√£o determin√≠stico. Outro erro foi quando falei que complexidade exponencial √© Big O de 2 elevado a N mas na realidade √© N elevado a N. E falando nisso eu disse que fatorial √© a complexidade mais cara, mas na realidade √© a exponencial, porque por exemplo, 15 fatorial √© 15 vezes 14 vezes 13 vezes 12 etc at√© 1. Mas 15 elevado a 15, exponencial, √© 15 vezes 15 vezes 15 etc 15 vezes.</p>
<p>Exemplo de trecho que tirei direto da cabe√ßa e n√£o revisei direito. Eu disse que um exemplo de complexidade fatorial √© a implementa√ß√£o do c√°lculo de fatorial recursivo. T√° errado e nem lembro porque eu falei isso, mas na realidade √© O linear e n√£o fatorial. O exemplo correto pra fatorial √© o Travelling Salesman, que eu traduzi direto do ingl√™s pra Vendedor Viajante mas no Brasil povo t√° acostumado a falar em problema do caixeiro viajante. Na real tanto faz, se voc√™ procurar em portugu√™s vai achar como caixeiro mesmo, mas eu recomendo procurar como travelling salesman que vai achar artigos muito melhores sobre o problema.</p>
<p>Tudo isso dito, vamos ver se neste √∫ltimo epis√≥dio da s√©rie eu cometo menos erros. Sempre leiam os coment√°rios, tem um povo que t√° prestando aten√ß√£o e corretamente corrigindo. Falando nisso eu fico surpreso que tem gente que acha que pessoas como eu n√£o erram. √ìbvio que erram e n√£o √© pouca coisa, no m√°ximo eu diria que pessoas experientes no geral reconhecem o erro mais r√°pido e corrigem mais r√°pido. Pessoal inexperiente, por alguma raz√£o, insiste no erro por muito mais tempo do que deveriam. No final todo mundo erra, ent√£o n√£o fiquem frustrados se voc√™s erram, o problema √© errar a mesma coisa o tempo todo.</p>
<p>Pra voc√™ n√£o se perder vamos recapitular. Ano passado eu adaptei dois v√≠deos de dois canais que eu gosto, do Ben Eater e do Gaming Mechanics Explained. Primeiro pra mostrar no n√≠vel do transistor, num protoboard, como bits s√£o armazenados numa mem√≥ria e como instru√ß√µes de "baixo n√≠vel" s√£o constru√≠das com transistores, a verdadeira linguagem de m√°quina. Tudo come√ßa com instru√ß√µes simples como soma, constru√≠do em hardware, passando el√©trons por transistores, formando portas l√≥gicas. E com isso voc√™ chega no Assembly.</p>
<p>Depois, de prop√≥sito, resolvi contar a hist√≥ria de Turing e Von Neumann pra explicar como instru√ß√µes e dados populam a mesma lingui√ßona de bits e o que isso significa, os prim√≥rdios da computa√ß√£o moderna. Na sequ√™ncia eu quis falar sobre tipos de arquivos, que todo mundo usa e ningu√©m entende que arquivos texto e arquivos execut√°veis √© tudo a mesma coisa, tudo um lingui√ß√£o de bits. Todo programa, todo arquivo, √© nada mais que um numeroz√£o gigante.</p>
<p>A ordem que esses bits aparecem nessa fita determina seu formato. Cada bit tem um endere√ßo, que √© a posi√ß√£o na fita. E quando voc√™ tem sequ√™ncias especiais de bits em determinados endere√ßos vai come√ßar a diferenciar entre uma imagem jpeg e um execut√°vel de Linux, por exemplo. Ali√°s, quando eu falei de mem√≥ria virtual nos dois √∫ltimos epis√≥dios, a divis√£o de segmentos como stack, heap, ROData, Text √© espec√≠fica de Linux e execut√°veis ELF. Windows e Mac o layout dos segmentos √© diferente, ou seja, o range de endere√ßos de cada coisa vai ser diferente. Mesma coisa entre arquiteturas de 32 ou 64-bits.</p>
<p>Enfim, da√≠ chegamos na trilogia de agora, onde comecei com diferentes Hello World pra mostrar como essa fita √© usada e como a mem√≥ria come√ßa a ser organizada em coisas como stack e heap e finalmente no √∫ltimo epis√≥dio mostrei como existem diferentes tipos de listas: arrays, listas ligadas, hashtables. N√£o cheguei a mencionar, mas voc√™ pode implementar Stacks que s√£o pilhas e Queues que s√£o filas usando qualquer uma dessas estruturas. N√∫meros inteiros, arrays de chars, e coisas assim s√£o tipos primitivos, coisas ‚Äúconcretas‚Äù. Pilhas ou filas s√£o conceitos, que podem ser implementados de v√°rios jeitos, e por isso chamamos de tipos abstratos.</p>
<p>Pilhas podem ser arrays ou listas ligadas onde voc√™ s√≥ tem acesso ao √∫ltimo elemento, no caso de pilha, ou seja, s√≥ opera√ß√µes de push pra empurrar um elemento pro fim da lista e pop pra tirar o elemento do come√ßo da lista. Filas voc√™ tamb√©m tem duas opera√ß√µes principais, uma enqueue pra colocar no fim da lista e uma dequeue pra tirar do come√ßo da lista. S√£o casos de estruturas que chamamos de lineares.</p>
<p>Ent√£o tamb√©m existem estruturas n√£o-lineares, e aqui entra o assunto de Grafos. Eu n√£o lembro se era correto dizer assim, mas um caso particular de Grafo unidirecional √© uma √Årvore. Voltando. Grafos voc√™ v√™ todos os dias. Toda rede, seja rede local ou de internet, √© um grafo. Um conjunto de n√≥s ou Nodes, como computadores, ligados por Edges que s√£o tipo o cabo ethernet pro roteador ou mesmo a conex√£o wifi que liga seu smartphone no roteador.</p>
<p>Uma rede social √© um grafo, onde os Nodes s√£o as pessoas. Os Edges s√£o os relacionamentos entre elas. E voc√™ pode ter todo mundo ligado com todo mundo ou diversos grupos ligados por algumas poucas pessoas em comum entre os grupos. Se quiser entender redes sociais, voc√™ come√ßa entendendo Grafos.</p>
<p>Mas grafos √© um assunto muito grande pra explicar em pouco tempo. Por hoje, entendam que existe essa mat√©ria pra estudar. Praticamente tudo que voc√™ chama de Rede pode ser descrito com grafos. Por exemplo, o algoritmo de como encontrar o caminho mais curto entre dois Nodes num Grafo, que √© o Shortest Path do Dijkstra. Poderia ser o caminho mais curto entre duas localiza√ß√µes num Google Maps ou o caminho mais curto no relacionamento de pessoas num LinkedIn.</p>
<p>E na estat√≠stica existem v√°rios estudos sobre as particularidades de distribui√ß√£o de diferentes grafos ou redes. Se quiser se aprofundar, recomendo livros de rede do Steven Strogatz e Duncan Watts, que inclusive tem um modelo que leva o nome deles, o modelo Watts-Strogatz. Entendendo redes de forma estat√≠stica voc√™ chega nos temas de small worlds ou mundos pequenos, os famosos seis graus de separa√ß√£o.</p>
<p>Acho que na faculdade o povo ensina at√© o modelo de Erd√∂s e R√©nyi. O tema de mundos pequenos explodiu por conta do aparecimento das redes sociais massivas no come√ßo do s√©culo XXI. Porque agora temos dados reais massivos pra analisar, o tal Big Data, que foi material de pesquisa pra um Duncan Watts quando trabalhou no Yahoo e hoje na Microsoft. Da√≠ voc√™ chega nos modelos de Watts-Strogatz e Barab√°si-Albert. Se voc√™ acha que entende redes sociais e nunca ouviu falar deles, ainda n√£o sabe o que s√£o redes sociais.</p>
<p>Isso tudo dito, deixa eu dar uns passos pra tr√°s. Depois de aprender arrays, listas ligadas e hashtables acho que √© importante fechar com √°rvores que, por si s√≥, √© um assunto bem grande, podemos ir pra B-trees que sendo honesto eu n√£o lembro mais tudo de cabe√ßa. B-trees √© o que t√° por tr√°s de √≠ndices de bancos de dados, por exemplo. Mas falando genericamente de √°rvores, voc√™ vai ver essa estrutura em tudo que √© lugar.</p>
<p>Exemplos simples? Basta ver seu Windows Explorer, Mac Finder ou GNOME Nautilus. Seu file system, o sistema de arquivos √© inteiro baseado em √°rvores. Diret√≥rios e arquivos s√£o Nodes na √°rvore, a ra√≠z pode ser o seu C:. Veja um documento HTML, qualquer p√°gina da Web. Sua representa√ß√£o √© o famoso DOM ou Document Object Model, uma √°rvore onde cada Node, ou entidade, s√£o elementos como par√°grafos, forms, imagens e tudo mais. E falando em objetos, veja um Java da vida cuja biblioteca √© toda herdada a partir da classe Object. Toda heran√ßa de classes e interfaces √© representada numa √°rvore.</p>
<p>E sem √°rvores voc√™ n√£o consegue seguir pras pr√≥ximas mat√©rias na ci√™ncia da computa√ß√£o como sistemas operacionais ou compiladores. Todo seu c√≥digo fonte, seja numa linguagem compilada como C ou interpretada como Python ou Javascript passa por etapas como an√°lise l√©xica, depois an√°lise sint√°tica, que gera coisas como um AST ou abstract syntax tree, que √© a representa√ß√£o do seu c√≥digo texto no formato de uma √°rvore. E mesmo pra entender sistemas operacionais voc√™ vai precisar de √°rvores.</p>
<p>Quando falei de mem√≥ria virtual vimos dois exemplos de segmentos importantes. Primeiro a stack, que controla o estado da execu√ß√£o do programa a cada instru√ß√£o e que √© implementado como uma estrutura de dados linear de Pilha. J√° o segmento Heap pode ser gerenciado com uma √°rvore. Na realidade o Heap usa uma estrutura de dados baseada em √°rvore chamada Heap. Um Heap pode ser uma implementa√ß√£o de um tipo de dados abstrato chamado Fila de Prioridade ou Priority Queue. S√£o mais tipos abstratos como a Pilha ou Fila, que podem ser implementadas com as estruturas de dados primitivas que expliquei antes.</p>
<p>Se for uma binary heap, ent√£o √© implementado usando uma binary tree, ou √°rvore bin√°ria. A distin√ß√£o √© importante porque nos exemplos de file system ou DOM de HTML as √°rvores n√£o s√£o bin√°rias, porque cada Node n√£o tem s√≥ dois elementos, eles podem ter m√∫ltiplos filhos ou at√© m√∫ltiplos pais, ent√£o s√£o grafos mas n√£o √°rvores bin√°rias. Provavelmente B-trees, que vou explicar o que s√£o mais pro final.</p>
<p>A estrutura de Heap √© a usada no algoritmo de ordena√ß√£o Heapsort. Lembram quando falei de Quicksort no epis√≥dio anterior? Tem outras nos livros de algoritmos como mergesort, insertion sort; e heapsort costuma aparecer junto. Mas o importante √© saber que sua mem√≥ria t√° organizada numa √°rvore bin√°ria.</p>
<p>Uma √°rvore tem como caracter√≠stica come√ßar de um Node ra√≠z ou Root. Root pra quem n√£o sabe, √© tradu√ß√£o pra ra√≠z, o primeiro Node. O primeiro usu√°rio num Linux chama Root, por isso. Quando voc√™ digita caminhos de diret√≥rios a primeira barra ao contr√°rio, backslash, a gente chama de root do file system. Num Windows o ‚ÄúC:\‚Äù s√≥ √© a ra√≠z do seu primeiro HD que o Windows sempre chama de C (e pra quem n√£o sabia √© porque A e B eram reservados pra drives de disquetes). Mas enfim, voc√™ vai ver esse nome root ou ra√≠z em v√°rios lugares.</p>
<p>Lembram da Lista Ligada? √â uma struct que tem um valor qualquer que queremos guardar e um ponteiro pra outro Node, o previous ou next no nosso exemplo. Numa √°rvore, cada Node vai apontar pra mais de um Node. Numa √°rvore bin√°ria, em particular, aponta pra 2 outros Nodes que comumente chamamos de <code>left</code> e <code>right</code> ou esquerda e direita.</p>
<p>Uma √°rvore pode ser balanceada ou n√£o-balanceada. Numa √°rvore bin√°ria, n√£o balanceada, onde vamos incluindo elementos, digamos, tudo pra direita da √°rvore, vai se comportar basicamente como uma lista ligada com complexidade O linear pra procura. Vamos dar um exemplo besta de √°rvore assim.</p>
<p>Pense numa lista de n√∫meros quaisquer como vinte e sete, quatorze, trinta e cinto, dez, dezenove, trinta e um e quarenta e dois. Agora vamos imaginar uma Struct Node com ponteiros left e right pra outros Nodes. E vamos desenhar como ficaria na mem√≥ria a vers√£o ineficiente, onde s√≥ vou preencher o ponteiro right de cada Node. Veja como elas ficam sequenciais como se fosse uma lista ligada.</p>
<p>√â o pior caso. Mas a coisa s√≥ fica interessante quando falamos em √°rvores bin√°rias balanceadas ou pelo menos semi-balanceadas. E nesse caso o tempo de procura vai ser proporcional ao height, ou altura da √°rvore em vez de ser proporcional ao total de elementos inseridos.</p>
<p>De exemplo, podemos desenhar a mesma sequ√™ncia mais bonitinho, de uma forma balanceada pra ter ambos left e right preenchidos. Veja como fica mais bonito, com uma altura tamanho 2, sem contar a raiz, em vez de ter altura 7 que era a altura da lista ligada. Mas at√© aqui n√£o ganhamos muita coisa a n√£o ser reorganizar a estrutura. Se eu quiser procurar onde t√° a chave 31 ainda ia precisar sair comparando quase todos os Nodes e a procura seria O linear do mesmo jeito que na lista ligada. Vamos ver como melhorar isso.</p>
<p>Eu falei antes que um dos problemas de um array √© quando queremos inserir um elemento no meio dele. Digamos, inserir na posi√ß√£o 5 de um array de 10 elementos. Tem duas formas. A primeira √© copiar os elementos da posi√ß√£o 6 at√© 10 uma posi√ß√£o mais pra frente - se ainda tiver espa√ßos vazios) e inserir o novo elemento na posi√ß√£o 6. Outra forma √© se for uma lista ordenada, da√≠ inserimos o novo elemento no fim do array e mandamos ordenar ele usando um Timsort ou Quicksort da vida.</p>
<p>Qualquer uma das formas pode ter uma complexidade maior que O linear, provavelmente loglinear que √© a complexidade de um algoritmo de ordena√ß√£o como Quicksort. Mas, e se fosse poss√≠vel inserir um elemento numa lista pr√©-ordenada em complexidade menor que linear, talvez logaritmica?</p>
<p>Apesar do nome √°rvore, e apesar da imagem na cabe√ßa ser algo como diret√≥rios e arquivos numa hierarquia, pense em √°rvores bin√°rias como se fosse uma lista mesmo. Aqui vem o neg√≥cio que se fala sempre sobre abstra√ß√µes. O objetivo √© o seguinte: ter uma lista ordenada que, no geral, √© mais barato de procurar e mais barato de inserir ou apagar elementos do que um array ou lista ligada.</p>
<p>√Årvores aparecem porque, como expliquei no video anterior, se temos um problema que podemos ir particionando, tipo quebrando uma lista ao meio, depois quebrando essa metade ao meio, isso √© caracter√≠stica de algo logar√≠tmico. Pense numa √°rvore visualmente como se fosse uma lista particionada. A ra√≠z poderia ser o elemento mais do meio da lista e cada um de seus filhos tem metade da lista e assim sucessivamente at√© o fim da lista.</p>
<p>Mas s√≥ particionar n√£o tem muita vantagem se a lista estiver bagun√ßada, tudo fora de ordem. O grande truque √© ter essa √°rvore com os itens ordenados. Por√©m, o que significa Nodes ordenados numa √°rvore que n√£o parece ter uma √∫nica dire√ß√£o? Quem √© o primeiro elemento? Quem √© o segundo? Vamos pegar essa sequ√™ncia de 14 n√∫meros aleat√≥rios e organizar numa √°rvore bin√°ria ordenada. Veja como o n√∫mero 0 t√° mais pra esquerda, o 34 virou a ra√≠z e mais pra direita tem n√∫meros maiores como 99.</p>
<p>O √∫nico c√≥digo que vou mostrar linha a linha hoje √© da binary search tree ou √°rvore de procura bin√°ria. Vamos come√ßar criando a struct Node, parecido com o da lista ligada e do hashtable. √â muito simples, tem um campo pro n√∫mero que vamos guardar. Da√≠ os ponteiros de left e right pros Nodes filhos. Agora vamos direto fazer uma fun√ß√£o main que vai popular essa √°rvore. Note que eu declarei a vari√°vel root s√≥ com o tipo Node em vez de <code>struct Node</code> como vim fazendo antes. Isso porque eu declarei ele como um novo tipo com <code>typedef</code> ent√£o <code>Node</code> √© a mesma coisa que <code>struct Node</code>. Fica mais curto de escrever e agora voc√™s j√° viram do outro jeito pra ver a vantagem de usar assim.</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
typedef struct Node {
    int data;
    struct Node* left;
    struct Node* right;
} Node;
Node* insert(Node *root, int data) {
    Node *temp = (Node*) malloc(sizeof(Node));
    temp-&gt;data = data;
    temp-&gt;left = NULL;
    temp-&gt;right = NULL;
    if (root == NULL) {
        root = temp;
    } else {
        Node *current = root;
        Node *parent = NULL;
        while(1) {
            parent = current;
            if (data &lt; parent-&gt;data) {
                current = current-&gt;left;
                if (current == NULL) {
                    parent-&gt;left = temp;
                    return root;
                }
            } else {
                current = current-&gt;right;
                if (current == NULL) {
                    parent-&gt;right = temp;
                    return root;
                }
            }
        }
    }
    return root;
}
Node* search(Node *root, int data) {
    Node *current = root;
    printf("Visiting elements: ");
    while(current) {
        printf("%d ", current-&gt;data);
        if (data &lt; current-&gt;data) {
            current = current-&gt;left;
        } else if (data &gt; current-&gt;data) {
            current = current-&gt;right;
        } else {
            return current;
        }
    }
}
void pre_order_traversal(struct Node* root) {
    if(root) {
        printf("%d ", root-&gt;data);
        pre_order_traversal(root-&gt;left);
        pre_order_traversal(root-&gt;right);
    }
}
void inorder_traversal(struct Node* root) {
    if(root) {
        inorder_traversal(root-&gt;left);
        printf("%d ", root-&gt;data);
        inorder_traversal(root-&gt;right);
    }
}
void post_order_traversal(struct Node* root) {
    if(root) {
        post_order_traversal(root-&gt;left);
        post_order_traversal(root-&gt;right);
        printf("%d ", root-&gt;data);
    }
}
int _print_t(Node *tree, int is_left, int offset, int depth, char s[20][255])
{
    char b[20];
    int width = 5;
    if (!tree) return 0;
    sprintf(b, "(%03d)", tree-&gt;data);
    int left  = _print_t(tree-&gt;left,  1, offset,                depth + 1, s);
    int right = _print_t(tree-&gt;right, 0, offset + left + width, depth + 1, s);
    for (int i = 0; i &lt; width; i++)
        s[2 * depth][offset + left + i] = b[i];
    if (depth &amp;&amp; is_left) {
        for (int i = 0; i &lt; width + right; i++)
            s[2 * depth - 1][offset + left + width/2 + i] = '-';
        s[2 * depth - 1][offset + left + width/2] = '+';
        s[2 * depth - 1][offset + left + width + right + width/2] = '+';
    } else if (depth &amp;&amp; !is_left) {
        for (int i = 0; i &lt; left + width; i++)
            s[2 * depth - 1][offset - width/2 + i] = '-';
        s[2 * depth - 1][offset + left + width/2] = '+';
        s[2 * depth - 1][offset - width/2 - 1] = '+';
    }
    return left + width + right;
}
void print_t(Node *tree)
{
    char s[20][255];
    for (int i = 0; i &lt; 20; i++)
        sprintf(s[i], "%80s", " ");
    _print_t(tree, 0, 0, 0, s);
    for (int i = 0; i &lt; 20; i++)
        printf("%s\n", s[i]);
}
int main() {
    int i;
    int array[] = { 34, 84, 15, 0, 2, 99, 79, 9, 88, 89, 18, 31, 39 };
    Node *root = NULL;
    for(i = 0; i &lt; 17; i++) {
        root = insert(root, array[i]);
        printf("Inseriu: %d\n", array[i]);
    }
    Node *temp = search(root, 30);
    if(temp) {
        printf("[%d] Element found.\n", temp-&gt;data);
    } else {
        printf("[x] Element (%d) not found.\n", i);
    }
    temp = search(root, 88);
    if(temp) {
        printf("[%d] Element found.\n", temp-&gt;data);
    } else {
        printf("[x] Element (%d) not found.\n", i);
    }
    printf("\nPreorder traversal: ");
    pre_order_traversal(root);
    printf("\nInorder traversal: ");
    inorder_traversal(root);
    printf("\nPost order traversal: ");
    post_order_traversal(root);
    printf("\n");
    print_t(root);
    return 0;
}
</code></pre>
<p>Come√ßamos com um array de 14 elementos, n√∫meros aleat√≥rios. E um Node chamado root pra ser a ra√≠z. Fazemos um loop pra inserir todos os elementos desse array na √°rvore. Ent√£o j√° sabemos que vamos precisar de uma fun√ß√£o chamada <code>insert</code>. S√≥ pra ficar mais f√°cil de explicar e n√£o precisar falar de ponteiro de ponteiros, a primeira vari√°vel vai ser o endere√ßo pra ra√≠z, que come√ßa nulo e a fun√ß√£o devolve o endere√ßo da ra√≠z de volta quando popular. Tem jeito melhor de fazer isso, mas pro exemplo isso √© suficiente.</p>
<p>Chegou a hora de tentar procurar um elemento dentro da √°rvore criando outra fun√ß√£o, a <code>search</code>. Mesma coisa dos outros epis√≥dios, vamos passar o endere√ßo da ra√≠z e o n√∫mero que tamos procurando. Agora vamos voltar l√° pro come√ßo do arquivo e criamos essas fun√ß√µes, come√ßando pela <code>insert</code> que vai receber um ponteiro pra ra√≠z e o n√∫mero que queremos inserir e retorna de volta o endere√ßo da ra√≠z.</p>
<p>Come√ßamos criando uma inst√¢ncia de Node no heap com malloc e associando o endere√ßo na vari√°vel <code>temp</code> de tempor√°rio. Da√≠ preenchemos a estrutura com o n√∫mero que passamos no campo <code>data</code> e inicializamos os ponteiros de left e right pra ser nulo. Ali√°s, importante, isso foi uma coisa que esqueci mesmo nos exemplos de lista ligada e hashtable. Se n√£o inicializar os ponteiros com NULL, explicitamente, nada garante que no espa√ßo alocado n√£o havia bits de outra coisa l√° e os campos podem come√ßar j√° preenchidos com lixo, apontando pra algum lugar aleat√≥rio bizarro. Das duas uma, ou eu inicializo na m√£o como fiz agora gravando NULL ou em vez de <code>malloc</code> posso usar <code>calloc</code> pra que j√° faz essa limpeza.</p>
<p>Voltando, o come√ßo √© simples. Se a raiz, ou root, for nula como √© o caso na primeira vez, ele passa a apontar pro mesmo lugar que a vari√°vel <code>temp</code>. Da√≠ termina o <code>if</code> e d√° return do novo root. Caso contr√°rio, vamos fazer uma cl√°usula <code>else</code> e come√ßamos criando um novo ponteiro tempor√°rio chamado <code>current</code> que aponta pro Node do root e outro ponteiro chamado <code>parent</code> de pai ou m√£e, tanto faz, que come√ßa nulo.</p>
<p>Come√ßamos fazendo um loop infinito com <code>while(1)</code>. Se a gente n√£o fizer nada dentro desse loop pra sair, vai ficar repetindo dentro do loop pra sempre. Dentro come√ßamos fazendo a vari√°vel <code>parent</code> apontar pra <code>current</code> que, na primeira passada do loop √© o primeiro Node que j√° t√° inserido. O truque come√ßa aqui.</p>
<p>Vamos checar dois casos, se o n√∫mero que queremos inserir agora for menor que o n√∫mero do parent. Se n√£o for, cai no <code>else</code> que √© o caso oposto, se o n√∫mero que estamos inserindo for maior ou igual ao do Node parent. No nosso exemplo, a ra√≠z √© o n√∫mero 34. O pr√≥ximo n√∫mero da lista √© 84. Ent√£o ele cai no bloco de else.</p>
<p>Nesse bloco fazemos a vari√°vel current apontar pra direita do Node atual, do 34. E agora podemos ter dois casos. Se o Node current for nulo ou se j√° tiver outro Node. Nesse caso do 2o item ele ainda √© nulo, ent√£o fazemos o ponteiro pra direita do node parent apontar pro tempor√°rio e sa√≠mos do loop dando return da ra√≠z de novo.</p>
<p>Vamos completar o c√≥digo com o pr√≥ximo item da lista que √© o 15. Vai ser um novo insert, passamos o root e o n√∫mero 15, da√≠ criamos um novo Node temp pra acomodar esse valor 15. Root n√£o √© nulo, ent√£o entramos no primeiro bloco <code>else</code>. Vari√°vel current aponta pro root, parent pra nulo. Entramos no <code>while</code> infinito. Agora fazemos a vari√°vel parent ser igual ao current porque vamos usar pra navegar pela √°rvore; e o parent sempre vai t√° apontando pro Node imediatamente acima dela. Fica mais f√°cil de entender tendo esse diagrama na cabe√ßa.</p>
<p>Agora checamos que 15 √© menor que o valor no Node parent, que √© ra√≠z 34, ent√£o o current vai ser o espa√ßo pra esquerda do Node atual. Por acaso, esse espa√ßo ainda t√° vazio, ent√£o vai passar a ser o Node 15 que acabamos de criar. Retornamos o root de novo e quebramos o loop infinito. E neste est√°gio temos uma lista com o 34 no topo, 15 na esquerda e 84 na direita. O c√≥digo de inser√ß√£o t√° completo, vamos testar mais uma vez com o pr√≥ximo n√∫mero da lista, o zero.</p>
<p>Come√ßamos no topo da fun√ß√£o insert, passando a raiz e n√∫mero 0. Criamos o node tempor√°rio que vai conter o zero, root n√£o √© nulo ent√£o seguimos criando o ponteiro current apontando pro Node 34 e parent nulo. Entra no loop infinito e come√ßamos com o parent igual ao current que √© a raiz.</p>
<p>Como zero √© menor que o parent, que √© o 34 ainda, fazemos o current ser o Node √† sua esquerda, que √© o 15. Sendo o current n√£o nulo, ent√£o sai desse bloco e chega ao fim do while. Como o loop √© infinito repetimos. Agora o parent vai ser o current 15. De novo, zero √© menor que o atual parent que √© 15 ent√£o fazemos o current ser o Node left √† esquerda. Agora n√£o tem ningu√©m l√°, √© nulo, e √© onde vamos colocar o node zero. Pronto, atribu√≠mos o left do parent 15 pra ser o node tempor√°rio zero e damos return pra sair do loop infinito.</p>
<p>Vou acelerar aqui do lado pra inserir os elementos que faltam, e a √°rvore vai ficando dessa forma. Obviamente n√£o fica bonitinho assim na mem√≥ria, mas cada Node tem ponteiros apontando pra at√© dois outros Nodes e podemos rearranjar num diagrama pra ficar visualmente assim. O importante √© o seguinte: come√ßa lendo do Node mais √† esquerda e vai indo pra direita. Come√ßa pelo zero, depois dois, nove, da√≠ quinze, dezoito, trinta e um e chegamos na ra√≠z trinta e quatro, continua pro trinta e nove, setenta e nove e vai indo at√© o noventa e nove. Notaram como a lista t√° ordenada?</p>
<p>Antes de mostrar como fica a fun√ß√£o search, acho que vale mostrar como pegar de volta a lista ordenada e mostrar na tela. Temos 3 formas de navegar por essa lista, pre order, post order e in order. Pre order come√ßa da raiz e vai pra esquerda primeiro, depois pra direita. Indo de cima pra baixo. Post order come√ßa do primeiro node mais √† direita, no caso o nove e vai subindo, de baixo pra cima.</p>
<p>In order, como o nome diz √© na ordem. E qualquer um desses casos √© simples usando recurs√£o. Primeiro vamos colocar na main a chamada pra fun√ß√£o inorder_traversal passando o node raiz. Precisamos criar essa fun√ß√£o. Ela come√ßa checando se o node passado √© nulo, se for, n√£o faz nada e retorna. Caso contr√°rio chama ela mesma passando o Node √† esquerda.</p>
<p>Com os nossos valores de exemplo, se a gente pensar como ficaria a Stack do programa, vamos come√ßar chamando inorder pro Node 34. Ela n√£o √© nula. Ent√£o chama ela mesma de novo passando o Node 15. Acumula no topo da Stack porque n√£o retornamos ainda. Agora o node continua n√£o sendo nulo, ent√£o chama ela de novo com o pr√≥ximo node √† esquerda, que √© o do zero. Empilha na Stack, de novo. E quando chamarmos outra vez, o Node zero n√£o √© nulo, ent√£o passamos o node √† esquerda dela que, agora √© nulo. Empilhamos.</p>
<p>Agora a fun√ß√£o vai receber nessa vari√°vel root um nulo, ent√£o o <code>if</code> vai ser verdadeiro, n√£o faz nada e retorna. Desempilha da Stack. Voltamos pra chamada anterior que vai continuar do Node 0 e dar <code>printf</code> na tela. Vai imprimir zero e agora vamos chamar a fun√ß√£o de novo passando quem t√° √† direita do Node 0, e tem o Node 2. Empilhamos.</p>
<p>Mesma coisa, prestem aten√ß√£o, O node n√£o √© nulo, agora chamamos a fun√ß√£o passando o ponteiro pro Node √† esquerda do 2, por acaso √© nulo. Empilhamos. J√° sabemos que o <code>if</code> vai checar a vari√°vel como nulo, n√£o faz nada e desempilha. Agora d√° <code>printf</code> pro 2 e chama a fun√ß√£o passando quem t√° √† direita do dois. Por acaso √© o Node 9. Empilha.</p>
<p>Mesma coisa, node n√£o √© nulo, chamamos a fun√ß√£o pro node √† esquerda do nove que √© nulo, j√° sabemos que vai empilhar, entrar e desempilhar porque √© nulo, ent√£o vamos pular e na sequ√™ncia vai dar <code>printf</code> do 9. Agora tenta chamar a fun√ß√£o pro Node √† direita do 9, que √© nulo. De novo, vai empilhar, checar que √© nulo, n√£o faz nada e desempilha. E acaba a fun√ß√£o pro 9, retorna e desempilha.</p>
<p>A fun√ß√£o do 2 tamb√©m termina, desempilha. A chamada pro zero tamb√©m acaba e desempilha. Voltamos pro Node 15. Agora continua dando <code>printf</code> pra ele, imprime 15 na sequ√™ncia do 9 e chama a fun√ß√£o pro node √† direita do 15, que vai ser o 18. Empilha. Node n√£o √© nulo ent√£o chama a fun√ß√£o pro node √† esquerda, que √© nulo, podemos pular porque sabemos que vai empilhar e desempilhar. Continua dando <code>printf</code> pro 18. Agora chama a fun√ß√£o pro Node 31 √† direita.</p>
<p>Pausa, agora olha s√≥, j√° imprimiu o zero, dois, nove, quinze, dezoito e o pr√≥ximo vai ser 31, tudo na ordem crescente, ordenadinho e se continuar fazendo a mesma coisa vai imprimir at√© o 99 na ordem. Se voc√™ nunca viu isso antes deve ter dado um n√≥ na cabe√ßa. Mas √© justamente isso que precisa acontecer, porque essa estrutura e esse jeito de operar n√£o √© intuitivo se voc√™ nunca estudou estruturas de dados. Por intui√ß√£o voc√™ vai parar nas listas lineares e nunca vai entender o que vem depois, que s√£o grafos.</p>
<p>Ao final, s√≥ de ter inserido um monte de n√∫meros aleat√≥rios na √°rvore bin√°ria conseguimos pegar os elementos j√° ordenados. O mesmo resultado poderia ser obtido inserindo os n√∫meros num array e passando um Quicksort da vida neles. Mas entenda a diferen√ßa. Se for considerar puramente s√≥ inser√ß√£o de novos valores, √© mais r√°pido colocar num array, porque √© complexidade O constante. J√° na √°rvore vai ser O logaritmico. Ou seja, a inser√ß√£o na √°rvore √© mais lenta.</p>
<p>Mas a compara√ß√£o √© injusta. A complexidade de inserir elementos numa √°rvore de procura bin√°ria √© O logaritmico porque ele j√° insere os elementos ordenados. J√° no array √© O constante pra inserir no fim porque n√£o estamos ordenando. Se tamb√©m quisermos o array ordenado a cada inser√ß√£o, precisaria rodar um quicksort no m√≠nimo uma vez no final, da√≠ vai ficar mais caro que O loglinear.</p>
<p>Quando o array estiver todo ordenado, podemos pesquisar usando procura bin√°ria. Eu n√£o vou mostrar c√≥digo, mas √© assim. O jeito ing√™nuo de procurar num array √© fazer um loop e ir comparando elemento a elemento da esquerda pra direita at√© achar o 88. Voc√™ ia precisar de 10 opera√ß√µes de compara√ß√£o pra chegar l√°. Mas tem um jeito mais r√°pido que s√≥ funciona se a lista j√° tiver sido ordenada antes.</p>
<p>Voc√™ pega o tamanho do array e divide por dois, no caso vai ser 7. Da√≠ pega o endere√ßo do primeiro elemento e soma pelo tamanho de cada elemento multiplicado por sete, que √© o elemento 39, mais ou menos no meio da lista. Agora compara, 88 √© menor que 39? N√£o √©, ent√£o j√° sabemos que n√£o t√° na metade √† esquerda do 39 e n√£o precisamos olhar nenhum deles. S√≥ de fazer isso j√° eliminamos metade da lista que n√£o precisamos nos preocupar.</p>
<p>Recursivamente fazemos a mesma coisa, √† direita do 39 temos 6 elementos sobrando, dividido por 2 s√£o 3, somado √† posi√ß√£o 7 chegamos na posi√ß√£o 10, que √© o meio da metade da direita. E vai ser o elemento 88 por acaso. Comparamos com o valor procurado 88 e j√° chegamos nele. Ou seja, com 2 opera√ß√µes de endere√ßo pra chegar no meio do meio e 2 opera√ß√µes de compara√ß√£o chegamos no 88. 4 opera√ß√µes no total, contra os 10 do jeito ing√™nuo, menos da metade do processamento. E isso porque essa lista √© muito pequena. Quanto maior a lista maior vai ser a economia.</p>
<p>Por isso tem vantagem trabalhar com listas ordenadas. Por√©m, como disse antes, custa O n vezes log de n, loglinear pra ordenar um array. E dependendo do algoritmo, pode custar espa√ßo na mem√≥ria pra fazer essa ordena√ß√£o. Um mergesort por exemplo, acho que era um que custava mais caro em espa√ßo extra pra conseguir ordenar.</p>
<p>Lembram da anima√ß√£o que mostrei de mergesort no epis√≥dio anterior? Vamos ver de novo. Est√£o vendo que ele vai guardando valores aqui embaixo? Isso √© o espa√ßo tempor√°rio que o mergesort gasta pra conseguir ordenar a lista em cima. Ent√£o, n√£o √© s√≥ velocidade de processamento pra se preocupar como tamb√©m espa√ßo tempor√°rio de mem√≥ria que se gasta. Agora pensa na √°rvore. Ela n√£o custa muito espa√ßo adicional pra ordenar, e custa literalmente O logaritmico, tudo bem que √© pra cada elemento, mas a complexidade √© uma ordem de grandeza mais r√°pida que qualquer ordena√ß√£o de array.</p>
<p>E uma vez tendo a √°rvore ordenada, a procura √© parecida com o que acabamos de fazer com procura bin√°ria de array. Vamos ver. Voltando ao exemplo, precisamos implementar a fun√ß√£o <code>search</code>, que vai come√ßar recebendo como argumento o Node raiz da √°rvore e o valor que estamos procurando, no caso o 88.</p>
<p>Criamos uma vari√°vel tempor√°ria chamada <code>current</code> apontando pro <code>root</code>. De novo criamos um loop com <code>while</code> que vai quebrar se o node current for nulo. E isso s√≥ vai acontecer se a gente navegar pela √°rvore e nenhum dos Nodes tiver o valor que procurado. Agora √© a mesma coisa que na busca bin√°ria de array. A inser√ß√£o garante que nossa √°rvore bin√°ria j√° t√° ordenada como acabei de mostrar.</p>
<p>Vamos comparar o n√∫mero 88 com o valor do current que √© a ra√≠z 34. Como n√£o √© menor, pula pro <code>else if</code>. Como √© maior faz o <code>current</code> ser o Node 84. Repete o loop. 88 ainda n√£o √© menor que 84, pula pro <code>else if</code> de novo e faz current ser o node √† direita, right, que √© o 99. Repete o loop. Agora sim, 88 √© menor que 99 ent√£o vamos fazer o current pegar o Node √† esquerda de 99, o ponteiro left. Repete o loop. Agora o Node que achamos n√£o √© menor, n√£o √© maior, ent√£o finalmente cai no √∫ltimo <code>else</code> e pronto, achamos o 88.</p>
<p>Em quantidade de compara√ß√µes √© equipar√°vel √† busca bin√°ria de array ordenado, ordem de grandeza Big O logaritmico porque ambos os casos estamos particionando. Entenda a rela√ß√£o. Inserir elementos no fim de um array √© r√°pido, O constante, caso tenha espa√ßos vazios sobrando no final. Se n√£o tiver, precisa criar um novo array maior e copiar os elementos da anterior pra ela. Complexidade O linear. Se quiser que a lista esteja ordenada pra conseguir procurar via busca bin√°ria, vai custar O loglinear de um quicksort da vida. No hashtable n√£o se ordena porque a posi√ß√£o depende do hashing da chave. A procura vai ser O linear tamb√©m.</p>
<p>Ent√£o a pesquisa numa √°rvore bin√°ria vai ser melhor do que num array, lista ligada ou hashtable. Tudo depende de pra que voc√™ vai usar a lista. Pra guardar os campos que vem num formul√°rio simples de cadastro, qualquer lista serve, s√£o poucos elementos. Mesmo na for√ßa bruta ing√™nua, a diferen√ßa √© pouca. Agora, pra gerenciar coisas como um cache de banco de dados, voc√™ vai escolher alguma coisa melhor que um hashtable ou uma √°rvore bin√°ria.</p>
<p>N√£o chegamos no fim da hist√≥ria. Essa nossa √°rvore bin√°ria rudimentar √© s√≥ a base. O caso ruim pra √°rvore bin√°ria, da forma como implementamos, √© tentar adicionar uma lista de n√∫meros consecutivos. Por exemplo, vamos come√ßar de novo a partir de 99 e tentar inserir cem. Como √© maior que 99, vai pra direita. Agora cento e um. Como √© maior que 99, vai pro 100. Sendo maior que 100, vai pra direita. Cento e dois, mesma coisa, quando chegar no cento e um, vai pra direita. E se continuarmos adicionando, olha como ficou nossa √°rvore. Parece um galho seco esperando pra cair, ficou basicamente como uma lista ligada, o pior caso.</p>
<p>Pior caso porque, sendo praticamente uma lista ligada, a complexidade pra procurar deixou de ser O logar√≠tmico e voltou a ser O linear. Ou seja, pra achar o √∫ltimo elemento, vai precisar comparar com todos os outros anteriores. Uma √°rvore assim √© desbalanceada. A gente precisa balancear e distribuir em outros galhos dessa √°rvore.</p>
<p>O que vimos at√© aqui √© chamado de √°rvore de procura bin√°ria ou binary search trees, cujo acr√¥nimo √© BST. O que costuma ensinar depois √© como balancear essas BSTs e uma das formas de fazer isso √© o que se chama de RBTrees ou Red Black Trees. Antes que algu√©m saia correndo pros coment√°rios, vou falar sobre AVLs j√° j√°, calma a√≠.</p>
<p>Uma das raz√µes de eu querer pular esse assunto √© porque realmente n√£o estou com vontade de explicar linha a linha de como se faz inser√ß√µes numa √°rvore Red Black. √â muito detalhezinho, vai dar um puta trampo pra editar e indo linha a linha num video vai ser ma√ßante pra caramba. Ent√£o, recomendo que voc√™s procurem o c√≥digo em qualquer linguagem e testem linha a linha na m√°quina de voc√™s. Em vez disso, vou fazer diferente aqui.</p>
<pre><code>#include&lt;stdio.h&gt;
#include&lt;stdlib.h&gt;
#define RED   'R'
#define BLACK 'B'
#define COUNT 10
typedef struct Node {
    int          key;
    char         color;
    struct Node *left;
    struct Node *right;
    struct Node *parent;
} Node;
// Based on CLRS algorithm, use T_Nil as a sentinel to simplify code
struct Node  T_Nil_Node;
Node* T_Nil = &amp;T_Nil_Node;
Node* Root = NULL;
// A utility function to create a new BST node
Node* newNode(int key)
{
    Node *temp   = (Node*) malloc(sizeof(Node));
    temp-&gt;key    = key;
    temp-&gt;color  = RED;
    temp-&gt;left   = NULL;
    temp-&gt;right  = NULL;
    temp-&gt;parent = NULL;
    return temp;
}
void rotateLeft( Node** T, Node* x)
{
    Node *y  = x-&gt;right;    // set y
    x-&gt;right = y-&gt;left;     // turn y's left subtree into x's right subtree{
    if (y-&gt;left != T_Nil)
        y-&gt;left-&gt;parent = x;
    y-&gt;parent = x-&gt;parent;  // link x's parent to y
    if (x-&gt;parent == T_Nil)
        *T = y;
    else if (x == x-&gt;parent-&gt;left)
        x-&gt;parent-&gt;left = y;
    else
        x-&gt;parent-&gt;right = y;
    y-&gt;left   = x;            // put x on y's left
    x-&gt;parent = y;
}
void rotateRight(Node** T, Node* y)
{
    Node *x  = y-&gt;left;     // set x
    y-&gt;left  = x-&gt;right;    // turn x's right subtree into y's left subtree{
    if (x-&gt;right != T_Nil)
        x-&gt;right-&gt;parent = y;
    x-&gt;parent = y-&gt;parent;  // link y's parent to x
    if (y-&gt;parent == T_Nil)
        *T = x;
    else if (y == y-&gt;parent-&gt;right)
        y-&gt;parent-&gt;right = x;
    else
        y-&gt;parent-&gt;left  = x;
    x-&gt;right  = y;         // put y on x's right
    y-&gt;parent = x;
}
void redBlackInsertFixup(Node** Root, Node* New)
{
    Node* temp;
    while (New-&gt;parent-&gt;color == RED)
    {
        if (New-&gt;parent == New-&gt;parent-&gt;parent-&gt;left)
        {
            temp = New-&gt;parent-&gt;parent-&gt;right;
            if (temp-&gt;color == RED)
            {
                temp-&gt;color = BLACK;
                New-&gt;parent-&gt;color = BLACK;
                New-&gt;parent-&gt;parent-&gt;color = RED;
                New = New-&gt;parent-&gt;parent;
            }
            else {
                if (New == New-&gt;parent-&gt;right)
                {
                    New = New-&gt;parent;
                    rotateLeft(Root, New);
                }
                New-&gt;parent-&gt;color = BLACK;
                New-&gt;parent-&gt;parent-&gt;color = RED;
                rotateRight(Root, New-&gt;parent-&gt;parent);
            }
        }
        else
        {
            temp = New-&gt;parent-&gt;parent-&gt;left;
            if (temp-&gt;color == RED)
            {
                New-&gt;parent-&gt;color = BLACK;
                New-&gt;color = BLACK;
                New-&gt;parent-&gt;parent-&gt;color = RED;
                New = New-&gt;parent-&gt;parent;
            }
            else {
                if (New == New-&gt;parent-&gt;left)
                {
                    New = New-&gt;parent;
                    rotateRight(Root, New);
                }
                New-&gt;parent-&gt;color = BLACK;
                New-&gt;parent-&gt;parent-&gt;color = RED;
                rotateLeft(Root, New-&gt;parent-&gt;parent);
            }
        }
    }
    Root[0]-&gt;color = BLACK;
}
void redBlackInsert(Node** T, int key)
{
    Node* z =  newNode(key);
    Node* y =  T_Nil;
    Node* x = *T;
    // Find where to Insert new node Z into the binary search tree
    while (x != T_Nil) {
        y = x;
        if (z-&gt;key &lt; x-&gt;key)
            x = x-&gt;left;
        else
            x = x-&gt;right;
    }
    z-&gt;parent = y;
    if (y == T_Nil)
        *T = z;
    else if (z-&gt;key &lt; y-&gt;key)
        y-&gt;left  = z;
    else
        y-&gt;right = z;
    // Init z as a red leaf
    z-&gt;left  = T_Nil;
    z-&gt;right = T_Nil;
    z-&gt;color = RED;
    // Ensure the Red-Black property is maintained
    redBlackInsertFixup(T, z);
}
#define MAX(a,b) (((a)&gt;(b))?(a):(b))
int height(Node* Root)
{
    int h = 0;
    if (Root != NULL) {
        if (Root == T_Nil)
            h = 1;
        else
        {
            int leftHeight  = height(Root-&gt;left);
            int rightHeight = height(Root-&gt;right);
            h = MAX(leftHeight, rightHeight) + 1;
        }
    }
    return h;
}
void printTree(Node* root)
{
    if (root-&gt;left != T_Nil)
        printTree(root-&gt;left);
    printf("%d ", root-&gt;key);
    if (root-&gt;right != T_Nil)
        printTree(root-&gt;right);
}
void padding ( char ch, int n ){
  int i;
  for ( i = 0; i &lt; n; i++ )
    putchar ( ch );
}
void structure ( struct Node *root, int level ){
  int i;
  if ( root == NULL ) {
    padding ( '\t', level );
    puts ( "~" );
  } else {
    structure ( root-&gt;right, level + 1 );
    padding ( '\t', level );
    if(root-&gt;color) {
        printf ( "%d,%c\n", root-&gt;key, root-&gt;color );
    } else {
        printf ( "%d,N\n", root-&gt;key );
    }
    structure ( root-&gt;left, level + 1 );
  }
}
int main(int argc, char* argv[])
{
    Node* Root = T_Nil;
    int list[14] = { 34, 84, 15, 0, 2, 99, 79, 9, 88, 89, 18, 31, 39 };
    //int list[10] = {1, 3, 2, 5, 4, 7, 6, 9, 8, 10};
    for (int i = 0; i &lt; 14; i++)
    {
        //printf("%d ", list[i]);
        redBlackInsert(&amp;Root, list[i]);
        printf("Inserindo %d\n", list[i]);
        structure(Root, 0);
    }
    printTree(Root);
    structure(Root, 0);
}
</code></pre>
<p>O que muda numa √°rvore bin√°ria normal e numa Red Black? Pra come√ßar o Node da √°rvore vai conter um campo extra de um bit, que pode ser zero ou um. Tanto faz se voc√™ chama zero de Red e um de Black ou vice versa, mas uma regra inviol√°vel √© que o Node raiz √© sempre preto.</p>
<p>Por padr√£o, todo Node novo que formos criando vai come√ßar sendo da cor vermelha. Mas depois de inserido na √°rvore precisamos checar a cor do pai e dos filhos, porque a regra √© que um Node vermelho s√≥ pode ter pais e filhos pretos. Se depois de inserir n√£o estiver assim, precisamos repintar os Nodes pra encaixar na regra. Parece estranho mas voc√™ vai entender.</p>
<p>Al√©m disso, todo Node no fim da √°rvore, que voc√™ pode chamar de folhas ou leafs, e terminaria com os ponteiros left e right sendo nulo, v√£o apontar pra um Node de servi√ßo que muitos nomeariam como Null Node ou TNil. Voc√™ pode chamar como quiser, mas √© um Node que serve s√≥ pros ponteiros left e right dos √∫ltimos Nodes n√£o serem nulo e seguir a regra das cores. Como √© tudo ponteiro, todo mundo no final vai s√≥ apontar pra esse Node mas no diagrama, pra ficar mais bonito, vai parecer que cada um t√° apontando pra um Node extra. S√≥ lembrem que √© tudo o mesmo Node TNil no final.</p>
<p>Uma das raz√µes de ter esses Nodes no final √© a regra que se contarmos todos os nodes entre a ra√≠z e esse Nulo deve sempre ter o mesmo n√∫mero de Node pretos. Na pr√°tica isso s√≥ vai acontecer se a √°rvore tiver a altura balanceada. Pra entender isso de balan√ßo considere nossa √°rvore bin√°ria de exemplo. Conseguem ver como alguns galhos pendem mais pra um lado s√≥? Os nodes 0 ou 15 pendem tudo pra direita. Do node 84 pende tudo pra esquerda.</p>
<p>Pra √°rvore ficar balanceada, precisamos fazer uma manuten√ß√£o, movendo ponteiros de lugar durante a inser√ß√£o. Lembra aquela ideia de fazer swap de ponteiro que eu falei no epis√≥dio anterior? √â parecido aqui. Swaps ou trocas, s√£o opera√ß√µes r√°pidas. S√≥ muda uns dois ou tr√™s ponteiros de lugar, independente da quantidade total de Nodes, ent√£o √© uma opera√ß√£o de complexidade O 1, constante.</p>
<p>Essa opera√ß√£o em √°rvores n√£o √© exatamente um swap, mas sim uma rota√ß√£o. E isso tudo dito, vamos dar um exemplo visual com a mesma lista de n√∫meros do exemplo, mas agora inserindo com o algoritmo de inser√ß√£o de uma √°rvore Red Black. O 34 √© a ra√≠z, por isso ela √© preta por padr√£o e seus ponteiros de left e right v√£o apontar praquele Node Nulo TNil. O pr√≥ximo n√∫mero √© 84, que por padr√£o entra vermelho e igual na √°rvore bin√°ria vai pra direita porque √© maior que 34. O pr√≥ximo n√∫mero 15 √© menor que 34 ent√£o vai pra esquerda e tamb√©m √© vermelho por padr√£o.</p>
<p>At√© aqui tudo bem, mas agora vamos inserir o n√∫mero 0. Pelas mesmas regras, √© menor que 34, menor que 15 ent√£o vai indo pra esquerda. E inserimos o Node zero vermelho. Mas a regra √© que um node vermelho n√£o pode ter um pai vermelho como o Node 15 em cima dele. Aqui come√ßa o trabalho de zeladoria recolorindo o Node 15 e o Node 84 pra preto. Agora a regra foi satisfeita.</p>
<p>Sobre o caminho mais curto que falei, olha s√≥. Quantos nodes pretos tem entre o 34 e o Nil embaixo do 0? 34 √© preto, 1. 15 √© preto, 2. 0 √© vermelho, continua 2, e nil √© preto, 3. Conseguem ver que qualquer outro caminho continua sendo 3 nodes pretos? Ent√£o as regras continuam satisfeitas. Vamos continuar tentando inserir o n√∫mero 2.</p>
<p>E aqui a coisa ficou diferente. Olha o que aconteceu. Tentamos inserir o n√∫mero 2. Pela regra da √°rvore bin√°ria, √© menor que 34 ent√£o vai pra esquerda. √â maior que zero ent√£o vai pra direita. Agora a √°rvore ficou desbalanceada. Por que? Pra come√ßar temos dois Node vermelhos um atr√°s do outro. E o irm√£o do Node 0, que √© o ponteiro pra direita do Node 15 t√° vazio. Isso n√£o pode acontecer, a ideia √© que os nodes mais pra cima tenham left e right preenchidos, evitando ponteiros nulos antes de chegar nas folhas. Precisamos fazer a tal rota√ß√£o.</p>
<p>Primeiro rotacionamos pra esquerda, subimos o Node 2 na √°rvore e descemos o Node 0 pra esquerda. Depois rotacionamos pra direita. Subimos o Node 2 pro mesmo andar da 15 e descemos o 15 pra direita. Finalmente repintamos o Node 2 e o Node 15 e pronto, voltamos a cumprir todas as regras do jogo. Nenhum Node vermelho tem pai ou filhos vermelhos e todos os caminhos do Node 34 at√© os nulos continua tendo o mesmo n√∫mero de Node pretos, no caso 3. Vamos continuar.</p>
<p>Os n√∫meros noventa e nove, setenta e nove e oitenta e oito v√£o sendo inseridos do mesmo jeito que na √°rvore bin√°ria. Mas agora vamos ver o 89. Mesma coisa, √© maior que 34, vai pra direita. √â maior que 84 vai pra direita. √â menor que 89, vai pra esquerda e, sendo maior que 88, vai pra sua direita. Alerta! Temos dois nodes vermelhos um atr√°s do outro e o irm√£o do 88, ou seja o ponteiro pra direita do 89 t√° vazio. Hora de rotacionar.</p>
<p>Come√ßa rotacionando pra esquerda, da√≠ o 89 passa a ser o pai de 88 e filho de 99. Rotacionamos pra direita e 99 passa a ser filho de 89 e irm√£o do 88. Vamos repintar o 88 e 89 e agora estamos cumprindo todas as regras de novo. Conseguem ver que se compararmos com a √°rvore bin√°ria de antes, agora parece visualmente mais balanceada? Ou seja, todos os Nodes antes do andar mais de baixo tem ambos os ponteiros left e right preenchidos, sem buracos sobrando.</p>
<p>Vamos continuar os outros n√∫meros at√© o fim da lista sem parar mais. Continuamos com dezoito, trinta e um e trinta e nove. Da√≠ escondemos os Nodes nulos no final pra ficar mais f√°cil de comparar. Olhem como a √°rvore Red Black e a √°rvore bin√°ria ficaram com um layout bem diferente. √â assim que uma √°rvore bin√°ria balanceada se parece usando o m√©todo de Red Black.</p>
<p>Em termos de espa√ßo extra sendo usado, √© barato. S√≥ um bit a mais pra cada Node, fora os ponteiros pro Node nulo no final de cada folha. E mesmo esse espa√ßo tem como economizar e vou falar disso j√° j√°. O tempo de inser√ß√£o √© definitivamente mais caro, mas ainda assim na ordem de grandeza de O logaritmico.</p>
<p>Ou seja, em compara√ß√£o com a √°rvore de procura bin√°ria, t√° um pouco mais lento, mas a ordem de grandeza de complexidade n√£o ficou muito mais caro. Procurar por itens nessa √°rvore √© a mesma coisa da √°rvore de procura bin√°ria. Uma busca bin√°ria. E pra apagar vai ser um pouco mais lento tamb√©m. Assim como na inser√ß√£o precisa manter a √°rvore balanceada, ent√£o toda vez precisa checar se precisa rotacionar e recolorir.</p>
<p>Como eu prometi, ainda temos √°rvores AVL pra comentar, que chama assim por causa dos autores Adelson-Velsky e EM Landis, de 1962. Em resumo, diferente do sistema de bit de cor do Red Black, cada Node num AVL tem um n√∫mero de balan√ßo que pode ser menos um, zero ou um, pra √°rvore ser balanceada. Se for mais que menos dois ou dois, a √°rvore t√° desbalanceada e precisa rotacionar e recalcular o balan√ßo.</p>
<p>Embora ambos AVL e Red Black tenham opera√ß√µes com complexidade na ordem de grandeza O logaritmico, a procura numa √°rvore AVL √© um pouco mais r√°pida, porque a Red Black ainda pode acabar menos balanceada que a AVL. A AVL √© mais agressiva em manter a √°rvore estritamente balanceada. A inser√ß√£o da AVL acaba sendo um pouco mais cara que a Red Black pra atingir isso. √â sempre um trade-off. Se voc√™ fizer mais inser√ß√µes do que procuras, um Red Black √© melhor. Se o tempo de inser√ß√£o n√£o for importante, mas pra voc√™ o tempo de procura for muito importante, ent√£o talvez AVLs sejam melhores.</p>
<p>Mais do que isso, diferente dos Nodes de Red Black que s√£o s√≥ 1 bit, os nodes de AVL precisam de dois bits extras, ent√£o vai ocupar um pouco mais espa√ßo na mem√≥ria. Al√©m disso, os Blacks tem outra vantagem dependendo da implementa√ß√£o. Lembram quando falei sobre n√∫meros inteiros com sinal e sem sinal? Se a gente souber que os n√∫meros que v√£o ser armazenados na √°rvore sempre √© positivo, podemos usar o primeiro bit, que normalmente seria pro sinal pra ser a cor do Node, da√≠ economizamos esse bit a mais na estrutura de Node.</p>
<p>E s√≥ pra piorar o caso do AVL, eu disse antes que as rota√ß√µes de Red Black s√£o simples, complexidade O 1 constante. Mas as inser√ß√µes de AVL podem ter mais rota√ß√µes mais complicadas, da√≠ o tempo varia mais. Por tudo isso, na d√∫vida, a escolha padr√£o acaba sendo Red Black, e AVL em casos especiais que voc√™ sabe que precisa das propriedades espec√≠ficas dele.</p>
<p>Vou deixar linkado na descri√ß√£o abaixo um documento do site da kernel do Linux que explica mais sobre como √°rvores Red Black s√£o usados no Kernel. Parafraseando, os schedulers de I/O deadline e CFQ usam rbtrees pra rastrear requisi√ß√µes. RBTree voc√™ lembra que s√£o Red Black Trees. O pacote de CD e DVD faz o mesmo. O c√≥digo de timer de alta resolu√ß√£o usa rbtrees. O filesystem ext3 rastreia diret√≥rios em uma rbtree. VMAs ou √°reas de mem√≥ria virtual usam rbtrees.</p>
<p>Seu Node.js e todo servidor com I/O ass√≠ncrono, por baixo usa o epoll do Linux. Rastreamento de descritores de arquivos, chaves criptogr√°ficas e scheduler de pacotes de rede usam rbtrees. S√≥ pra comparar, lembram nosso c√≥digo de exemplo de procura numa √°rvore bin√°ria? Vamos ver como essa documenta√ß√£o do site da kernel sugere fazer. E olha s√≥, √© bem parecido n√©? As mesmas compara√ß√µes pra esquerda, pra direita ou quando encontra o Node. Meu exemplo foi rudimentar mas a estrutura b√°sica √© a mesma nos casos mais complexos.</p>
<p>N√£o sei porque as linguagens mais populares interpretadas n√£o tem √°rvores Red Black por padr√£o. Eu diria que elas deveriam, porque assim como outras estruturas de dados, seriam melhor implementadas em C ou C++ do que em alto n√≠vel como Javascript ou Python. A classe <code>std::map</code> do C++ implementa √°rvores Red Black, assim como as classes TreeSet ou TreeMap do Java. Se for uma linguagem compilada como Go ou Rust, voc√™ pode baixar do GitHub alguma uma implementa√ß√£o que funciona em boa velocidade porque s√£o compiladas. Mas tirando Java e C++ n√£o sei de nenhuma outra que j√° vem embutida. Se algu√©m souber mande nos coment√°rios.</p>
<p>Mas lembrem-se, √°rvores Red Black e AVL tem como objetivo chegar numa √°rvore de procura bin√°ria, como no nosso exemplo anterior, mas balanceadas. Os algoritmos de inser√ß√£o que usam o sistema de cores ou balan√ßo e rota√ß√£o servem pra nos dar uma √°rvore balanceada que vai oferecer o menor tempo m√©dio de procura bin√°ria. Mas o que vimos at√© agora continua sendo uma √°rvore de procura bin√°ria, com Nodes que s√≥ tem um valor e dois ponteiros, um pra esquerda e outro pra direita.</p>
<p>Depois disso ainda existe a B-Tree que √© uma estrutura de √°rvore que tamb√©m √© auto-balanceada, ou seja, durante a inser√ß√£o e remo√ß√£o de Nodes ele faz a zeladoria de se rebalancear. Mas em vez de Nodes que s√≥ tem dois filhos, num B-Tree os Nodes podem ser X filhos maiores que 2. E mais coisas que n√£o vou detalhar aqui. A defini√ß√£o vem do livro do Knuth e todo mundo usa a mesma, ent√£o pesquisem sobre B-Trees como li√ß√£o de casa. Visualmente √© algo como nessa imagem do lado. Ainda uma √°rvore, idealmente balanceada, mas com mais filhos por Nodes.</p>
<p>E indo mais longe chegamos na B PLUS Trees, que voc√™ pode pensar como B-Trees mas onde os Nodes n√£o cont√©m os valores em si. Em vez disso, aponta pra folhas, e esse nodes folha √© que v√£o ter os valores que voc√™ quer armazenar. Os Nodes pais v√£o ter s√≥ as chaves que identificam esses valores. E √© essa √°rvore que voc√™ vai ver em tudo que usa armazenamento orientado a blocos.</p>
<p>Eu t√¥ pensando em fazer um epis√≥dio falando sobre blocos de armazenamento. √â por isso que se voc√™ j√° brincou com AWS ou Google Cloud ou Azure, j√° deve ter visto o termo ‚Äúblock storage‚Äù pra identificar HDs virtuais. Por agora s√≥ entenda que √© isso que faz B+ Trees serem ideais pra coisas como filesystems e bancos de dados. Tudo que voc√™ imaginar que armazena dados em disco provavelmente √© uma B+ Tree ou deriva√ß√£o. Exemplo. Os filesystem de Linux como ReiserFS, EXT4. O NTFS do Windows. O APFS dos Macs. A maioria dos bancos de dados relacionais como DB2, SQL Server, Oracle, SQLite e por a√≠ vai. √â tudo B+ Trees.</p>
<p>Falando em bancos de dados. Pra entender como os dados s√£o armazenados em disco, voc√™ precisa entender B+ Trees. Se voc√™ j√° usou qualquer MySQL ou Postgres da vida vai lembrar que tem a boa pr√°tica de sempre criar √≠ndices pra melhorar o tempo das suas pesquisas. E se voc√™ leu stackoverflow o suficiente tamb√©m vai lembrar que povo fala pra n√£o sair criando √≠ndice pra tudo que √© lado, como se n√£o houvesse amanh√£, sen√£o vai acabar com a performance. E a√≠ voc√™ fica sem saber o que fazer, cria ou n√£o cria √≠ndices ent√£o?</p>
<p>Se voc√™ entendeu a ideia de pegar uma lista e colocar numa √°rvore de procura bin√°ria balanceada e a id√©ia de hashing da hashtable do epis√≥dio anterior, meio que j√° entendeu uma parte da charada. O que s√£o registros de um banco? Pense como se fosse uma struct de C, como as que usamos em todos os exemplos at√© agora. Agora pense em gravar os bits de inst√¢ncias de structs no disco em vez da mem√≥ria. Uma tabela de banco de dados grande pode ter milhares ou milh√µes de registros. Seria bem lento sair procurando registro a registro como numa lista ligada. Mesmo se for uma √°rvore.</p>
<p>Diferente de ler da mem√≥ria, pense que num disco mec√¢nico voc√™ precisa sair ca√ßando bits em trilhas num disco. E ficar ca√ßando endere√ßos assim ia ser bem demorado. Mas se n√£o tem nenhum √≠ndice, √© isso que vai acontecer mesmo. Pelo menos fazendo uma busca bin√°ria, voc√™ vai eliminando uma boa parte de registros que n√£o precisa vasculhar, mas em milh√µes de registros, mesmo com busca bin√°ria vai ser devagar. √â o que muitos j√° devem ter visto nos seus bancos de dados favoritos quanto a pesquisa cai num table scan.</p>
<p>Quando voc√™ procura por chave prim√°ria ou por um campo indexado √© bem mais r√°pido. Pense num √≠ndice como uma segunda √°rvore, uma B-tree que √© a tal √°rvore onde cada Node pode ter v√°rios filhos, e √© auto-balanceada, ou seja, inser√ß√µes e dele√ß√µes re-balanceiam a √°rvore via opera√ß√µes como rota√ß√£o. Ela fica mais compacta porque √© como se fosse uma c√≥pia da sua tabela s√≥ que com os campos indexados.</p>
<p>Imagina num exemplo simples de √°rvore de procura bin√°ria, como esse na imagem aqui do lado. Se eu fizer uma pesquisa pra achar todos os sal√°rios maiores que 10 mil, depois de eliminar a metade esquerda da √°rvore. Agora temos os IDs ou endere√ßos de onde esses registros est√£o na outra √°rvore no disco, e podemos buscar s√≥ elas.</p>
<p>E porque n√£o √© bom criar um mont√£o de √≠ndices? Pense em inserir uma tabela como inserir numa √°rvore Red Black. Pra manter a √°rvore balanceada, pra acelerar pesquisas, voc√™ precisa repintar e rotacionar toda hora. Cada √≠ndice da sua tabela √© como se fosse uma √°rvore dessas. Quanto mais √≠ndices tiver, mais caro fica inserir em v√°rias delas, porque voc√™ precisa inserir na tabela propriamente dita e depois atualizar cada um dos √≠ndices que voc√™ criou. √çndices s√£o bons pra acelerar as pesquisas, mas o custo √© aumentar o pre√ßo de opera√ß√µes de inserts, updates e deletes.</p>
<p>De qualquer forma o objetivo de hoje n√£o √© detalhar como bancos de dados funcionam, mesmo porque eu mesmo n√£o sei tudo de cabe√ßa Mas s√≥ de saber que seu sistema de arquivos, seu banco de dados usam uma implementa√ß√£o de B+ Trees e que os √≠ndices que tornam suas pesquisas mais r√°pidas e suas inser√ß√µes mais lentas, provavelmente √© uma implementa√ß√£o de B-Trees, j√° vai ajudar voc√™ a procurar mais material pra estudar.</p>
<p>Uma √∫ltima coisa √© n√£o confundir B-Trees com Binary Trees ou √°rvores bin√°rias. Esse B √© de Balanced Trees, √°rvores balanceadas. E balancear √°rvores tem um custo, as tais opera√ß√µes de rota√ß√£o por exemplo. Mas no fim do dia, embora voc√™ pense visualmente numa √°rvore como uma hierarquia, na verdade √© uma lista ordenada, como um array ou uma lista ligada, mas estruturada de forma diferente. De forma n√£o linear.</p>
<p>A complexidade de cada tipo de algoritmo em cada tipo de estrutura de dados tem complexidades diferentes de processamento e uso de recursos. Alguns s√£o r√°pidos mas consomem mais mem√≥ria. Outros s√£o mais devagar na inser√ß√£o mas mais r√°pidos na procura. Casos excepcionais podem fazer um algoritmo O logaritmico cair pra O linear ou at√© mesmo O loglinear.</p>
<p>Outras coisas que voc√™ deve prestar aten√ß√£o. Se voc√™ partir do zero, de C, sozinho, √© poss√≠vel que compreenda um pouco sobre as complexidades de manipular e procurar elementos num array. Com um pouco de pr√°tica, vai naturalmente chegar numa lista ligada. Acho dif√≠cil chegar num Quicksort sozinho, mas se por acaso esbarrar em algum texto sobre particionamento e logaritmos, talvez chegue em algo parecido pra ordena√ß√£o e busca bin√°ria. John Von Neumann chegou no mergesort.</p>
<p>Se voc√™ se esfor√ßar bastante, talvez consiga evoluir da lista ligada e array pra hashtable e √°rvore de procura bin√°ria desbalanceada que vimos hoje. Mas eu acho muito improv√°vel voc√™ sozinho, sem a ajuda de nenhum livro, chegar na id√©ia de √°rvore balanceada e mecanismos como Red Black, AVL ou mesmo B-Trees. Pra isso voc√™ precisa de mais literatura. Especialmente porque conceitos como coloriza√ß√£o e rota√ß√£o n√£o s√£o intuitivos, mesmo se voc√™ j√° tiver a id√©ia de swap de vari√°veis na cabe√ßa.</p>
<p>A ideia de coloriza√ß√£o n√£o √© usada s√≥ em √°rvores Red Black. Um dos mecanismos de Garbage Collectors se chama TriColor Marking, onde a fase de marca√ß√£o de objetos categoriza quem pode ou quem n√£o pode ser descartado usando um sistema de tr√™s cores, preto, branco e cinza. Se voc√™ entendeu a ideia do vermelho e preto, j√° tem uma no√ß√£o de TriColor marking. Talvez eu fale sobre isso se for explicar como funcionam os garbage collectors em alto n√≠vel , mas por hoje fica a dica.</p>
<p>Eu espero que pelo menos tenha conseguido fazer voc√™s que s√£o iniciantes enxergarem um pouco mais de como as coisas funcionam por baixo do seu Javascript e Python. Mesmo que n√£o usem diretamente no trabalho, reservem um tempinho pra estudar o b√°sico de C. Especialmente porque se voc√™s se empolgarem, C e C++ v√£o ser √∫teis caso um dia queiram usar uma biblioteca em C dentro do Javascript. E sim, isso √© poss√≠vel e √© como muitas bibliotecas s√£o feitas de verdade.</p>
<p>O nosso lingui√ß√£o de bits sozinho √© s√≥ isso, bits um atr√°s do outro. Mas quando definimos estruturas de dados, come√ßamos a dar forma a peda√ßos desses bits. Delimitamos essas estruturas pelo tamanho de cada primitiva, como inteiros de 32 ou 64 bits, e os endere√ßos em que elas se localizam no lingui√ß√£o. Os bits sozinhos n√£o significam nada. S√≥ quando n√≥s programadores definimos o que cada peda√ßo √© que ela come√ßa a ter sentido. Por exemplo, uma sequ√™ncia de inteiros um atr√°s do outro pode ser um array s√≥ de n√∫meros mesmo ou de letras, formando um String, quem decide qual √© qual sou eu, programador.</p>
<p>Um pacote de bits que tem codificado um n√∫mero que √© outra posi√ß√£o no lingui√ß√£o, √© um Node. E esses Nodes podem ser organizados como listas ligadas, hashtables ou √°rvores. Da√≠ vem o problema de navegar por esses pacotinhos de bits. O jeito simples √© sequencialmente como num array, mas logo a gente v√™ que isso √© limitado. Da√≠ sa√≠mos pulando de endere√ßo pra endere√ßo de Nodes. Mas isso √© lento e complexo. A√≠ temos que inventar formas de minimizar esse trabalho e chegamos em algoritmos como de ordena√ß√£o e procura.</p>
<p>E √† medida que evolu√≠mos o conceito, uma √°rvore desbalanceada se torna balanceada. Uma procura que levava tempo linear vira logaritmico. E uma estrutura que era simples, vai ficando mais sofisticada. Sa√≠mos de heaps de mem√≥ria at√© √≠ndices de bancos de dados com a mesma categoria de estruturas e algoritmos. O importante √©: mesmo se voc√™ treinasse por anos a fio, sem estudar a funda√ß√£o, nunca vai chegar no que vimos nesses √∫ltimos 3 epis√≥dios sozinho. E ia continuar fazendo errado sem saber porque. ‚ÄúMeu programa t√° lento, deve ser meu CPU que √© velho‚Äù. E esquece que anos atr√°s se fazia programas que rodam mais r√°pido que o seu em CPU ainda mais velho. Ent√£o o problema n√£o √© o hardware n√£o ser o suficiente, mas sim voc√™ n√£o saber usar o m√°ximo que ele pode oferecer e se limitar a se conformar com ‚Äúah, pelo menos roda‚Äù.</p>
<p>Tudo que falei at√© aqui √© o b√°sico. Cada assunto que falei tem bem mais detalhes por tr√°s. E mesmo quando voc√™ tiver estudado tudo, ainda assim n√£o vai fazer programas bons. Mas ao longo do seu treino e estudos, as pe√ßas v√£o come√ßar a se encaixar mais r√°pido e voc√™ vai come√ßar a dar saltos maiores do que quem come√ßou junto com voc√™ mas preferiu pular essa teoria toda. Peguem o livro do Cormen, Tanenbaum e estudem. √â chato pra caramba, mas quanto mais cedo fizer isso, melhor vai ser depois.</p>
<p>E com isso, finalmente cheguei no final deste assunto. Como eu disse no come√ßo, assistam esta s√©rie m√∫ltiplas vezes. Se voc√™ √© iniciante, n√£o vai entender vendo s√≥ uma vez e nem tem tudo aquia. Precisa pesquisar mais sobre os assuntos que falei, fazer voc√™ mesmo esses c√≥digos como exerc√≠cio e s√≥ assim come√ßar a apreciar como as coisas funcionam. Se acharem algum erro no video n√£o deixem de mandar nos coment√°rios abaixo, se curtiram o video deixem um joinha, assinem o canal e cliquem no sininho pra n√£o perder os pr√≥ximos epis√≥dios. Compartilhem o video com seus amigos pra ajudar o canal. A gente se v√™, at√© mais.</p>
<p></p>