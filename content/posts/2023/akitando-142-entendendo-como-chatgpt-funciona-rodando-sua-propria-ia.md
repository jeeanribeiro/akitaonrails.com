---
title: "[Akitando] #142 - Entendendo COMO ChatGPT Funciona - Rodando sua Pr√≥pria IA "
date: "2023-06-19T20:47:00.000Z"
tags: ["openai", "vicuna", "llama", "gpt", "transformers", "pytorch", "tensorflow", "akitando"]
years: "2023"
---

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/O68y0yRZL1Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p>
<p>N√£o, AGI n√£o est√° pr√≥ximo de acontecer.</p>
<p>Quais s√£o os limites da atual tecnologia de transformadores generativos pr√©-treinados, vulgo GPT?
  O que s√£o os tais "modelos" que eles usam?
  O que s√£o os tais "par√¢metros".
  Porque as IAs parecem humanas nas respostas?
  IAs v√£o substituir programadores??
  Como √© poss√≠vel conseguir rodar um clone de ChatGPT na sua pr√≥pria m√°quina, totalmente offline?</p>
<p>Vamos responder tudo isso e muito mais.</p>
<h2>Cap√≠tulos</h2>
<ul>
  <li>00:01:07 - CAP 01 - Minha IA PESSOAL e OFFLINE - text-generation-webui</li>
  <li>00:06:37 - CAP 02 - Introdu√ß√£o a MODELOS - Como IA Aprende?</li>
  <li>00:10:09 - CAP 03 - Auto-Corretor de Teclado de Celular - Cadeias de Markov</li>
  <li>00:15:34 - CAP 04 - 170 TRILH√ïES de par√¢metros - Maior que nosso c√©rebro?</li>
  <li>00:20:28 - CAP 05 - De Markov a IA - O que s√£o Tensors?</li>
  <li>00:30:53 - CAP 06 - A Revolu√ß√£o da Auto-Aten√ß√£o - O que s√£o Transformers?</li>
  <li>00:35:24 - CAP 07 - Hardware pra Treinar IA - NVIDIA</li>
  <li>00:42:09 - CAP 08 - Par√¢metros e Sinapses s√£o equivalentes? - Quantiza√ß√£o</li>
  <li>00:49:42 - CAP 09 - Estamos pr√≥ximos de AGI? IAs s√£o Inteligentes?</li>
  <li>00:52:10 - CAP 10 - Controlando Criatividade de IAs - Temperatura</li>
  <li>01:00:27 - CAP 11 - A Av√≥ do ChatGPT - Eliza</li>
  <li>01:04:29 - CAP 12 - IAs que fazem Imagens - Diffusion</li>
  <li>01:09:31 - CAP 13 - Discutindo PROMPTs - LangChain</li>
  <li>01:13:08 - CAP 14 - IAs v√£o matar programadores? Quais os Limites?</li>
  <li>01:22:15 - CAP 15 - Virando "Programador 10x" com aux√≠lio de IAs - Copilot</li>
  <li>01:23:47 - CAP 16 - CONCLUS√ÉO - O come√ßo da BOLHA</li>
  <li>01:28:18 - Bloopers</li>
</ul>
<h2>Links</h2>
<ul>
  <li><a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">Introducing LLaMA: A foundational, 65-billion-parameter language model (facebook.com)</a></li>
  <li><a href="https://github.com/NVIDIA/Megatron-LM">NVIDIA/Megatron-LM</a></li>
  <li><a href="https://github.com/oobabooga/text-generation-webui">oobabooga/text-generation-webui</a></li>
  <li><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ">TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">Neural networks - YouTube</a></li>
  <li><a href="https://towardsdatascience.com/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253">GPT-4 Will Have 100 Trillion Parameters ‚Äî 500x the Size of GPT-3 | by Alberto Romero | Towards Data Science</a></li>
  <li><a href="http://introtodeeplearning.com/">MIT Deep Learning 6.S191 (introtodeeplearning.com)</a></li>
  <li><a href="https://www.youtube.com/watch?v=i9ikne_9iEI&amp;t=1646s">DF Direct Special: Starfield Tech Breakdown - 30FPS, Visuals, Rendering Tech + Game Impressions - YouTube</a></li>
  <li><a href="https://www.youtube.com/watch?v=It9D08W8Z7o&amp;t=102s">NVIDIA Made a CPU.. I‚Äôm Holding It. - YouTube</a></li>
  <li><a href="https://twitter.com/miolini/status/1634982361757790209">(2) Artem Andreenko üá∫üá¶ on Twitter: "I've sucefully runned LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware. https://t.co/XDbvM2U5GY" / Twitter</a></li>
  <li><a href="http://scihi.org/emile-borel-infinite-monkey-problem/">√âmile Borel and the Infinite Monkey Problem | SciHi Blog</a></li>
  <li><a href="https://github.com/codeanticode/eliza">GitHub - codeanticode/eliza: The classic Eliza psychologist program, implemented as a Processing library.</a></li>
  <li><a href="https://www.instagram.com/stories/highlights/18020038894467644/">Stories ‚Ä¢ Instagram</a></li>
  <li><a href="https://huggingface.co/TheBloke">TheBloke (Tom Jobbins) (huggingface.co)</a></li>
  <li><a href="https://python.langchain.com/docs/get_started/introduction.html">Introduction | ü¶úÔ∏èüîó Langchain</a></li>
</ul>
<p></p>
<p></p>
<h2>SCRIPT</h2>
<p>Ol√° pessoal, Fabio Akita</p>
<p>Este √© um epis√≥dio que eu tava tentando evitar fazer. Primeiro porque acho que vai ser um dos temas onde parte do video vai acabar ficando obsoleto meio r√°pido, j√° que as tecnologias de IA est√£o acelerando e mudando bastante ainda. Segundo, porque eu mesmo nunca trabalhei com IA. Maioria das coisas que explico neste canal, j√° me envolvi em projetos reais de alguma forma, por isso n√£o √© s√≥ teoria, √© experi√™ncia. Mas IA, eu brinquei, mas nunca trabalhei nem fiz pesquisa acad√™mica, nem nada disso, por isso nunca me senti adequado pra explicar.</p>
<p>Mas considerando que quase a totalidade de videos feitos sobre o assunto hoje s√£o de pessoas com menos conhecimento ainda, fazendo afirma√ß√µes cada vez mais absurdas; at√© eu certamente consigo fazer muito melhor. Pra variar, os oportunistas j√° sa√≠ram lan√ßando cursos e afins. No fim do video vou explicar porque todos s√£o uma droga e voc√™ deve evitar. Tamb√©m vou explicar de novo porque ela n√£o vai substituir programadores. Hoje vou explicar o que de fato √© um ChatGPT e onde estamos quando se fala em IA. Ent√£o vamos l√°.</p>
<p>(...)</p>
<p>Esses dias resolvi brincar de IA, o objetivo era ter o meu pr√≥prio ChatGPT, rodando offline, totalmente local, na minha m√°quina, sem conectar com nenhuma API de terceiros como da OpenAI. Isso ficou f√°cil porque agora existem diversos esfor√ßos da comunidade de c√≥digo aberto, em particular projetos de Open LLM, ou Large Language Models, que √© a categoria de IA onde se encontra um GPT.</p>
<p>Esses esfor√ßos ganharam for√ßa quando a Meta decidiu abrir seu modelo Llama em fevereiro de 2023. As big tech tem diversos modelos prontos, cada um pra algum uso espec√≠fico, desde respostas gerais ou mais focados em c√≥digo e assuntos espec√≠ficos. Por exemplo, a OpenAI tem os modelos GPT 3.5, GPT 4, Codex. A Microsoft tem o Zero, ou Megatron em conjunto com a NVIDIA. O Google tem modelos como o BERT, Palm, LaMDA, Minerva e outros.</p>
<p>A Meta, de novo, tem o OPT, Galactica, METALM, LLaMA. Alguns desses modelos s√£o citados em papers mas s√£o fechados, como o novo BARD do Google ou o pr√≥prio GPT 4 da OpenAI. Mas o lan√ßamento do LLaMA ao p√∫blico foi um evento importante e a Meta parece que liberou v√°rios outros como o OPT e Galactica. A primeira parte do video de hoje vai ser entender o que diabos s√£o esses modelos.</p>
<p>Isso foi em fevereiro, este video t√° saindo em junho, s√≥ 4 meses. E de l√° pra c√° a comunidade usou o LLaMA pra criar derivados mais otimizados e menores pra rodar em computadores menos parrudos. Surgiram diversas variantes como Alpaca, Vicuna, GPT4ALL, Koala, Dolly e dezenas de outros. Literalmente dezenas. O site HuggingFace, que √© um reposit√≥rio de modelos e ferramentas pra intelig√™ncia artificial, tem listado uns 200 modelos diferentes.</p>
<p>O que d√° pra fazer com esses modelos abertos? Deixa eu mostrar. Eu queria um ChatGPT pessoal, offline, que ningu√©m sabe o que t√¥ conversando com ele, sem filtros, sem controle, sem nada. S√≥ eu e a ferramenta. Existem v√°rios projetos abertos que implementam interface web similar ao ChatGPT, onde posso digitar perguntas, ver as respostas da IA, e ficar conversando com ela, sem precisar estar conectado na internet. Olha s√≥ esse exemplo.</p>
<p>(... screencast text-generator ...)</p>
<p>Se assistiram meu epis√≥dio sobre games em m√°quina virtual, sabem que tenho uma m√°quina que alguns consideram "parruda", um AMD 5950X de 16 cores, 32 threads, rodando a uns 4 gigahertz por core. Mais 64 gigabytes de RAM DDR4. Uma GPU NVIDIA RTX 3090 com 24 gigabytes de mem√≥ria GDDR5. Fora meu NAS Synology de 60 terabytes, conectado em rede 10 gigabits. Meus testes foram feitos numa m√°quina virtual QEMU rodando Ubuntu normal, com passthrough de PCI pra ter acesso direto √† GPU NVIDIA. Todos os detalhes sobre essa QEMU eu mostrei no video de Games em M√°quina Virtual.</p>
<p>Sem nenhum motivo em particular, escolhi o projeto aberto "text-generation-webui" que √© uma aplica√ß√£o web escrita em Python. Ela simula a interface web de chat do ChatGPT. Por baixo, carrega bibliotecas como bitsandbytes, pytorch e outros que vou explicar depois. Da√≠ podemos baixar modelos e fazer ele carregar um deles. No caso estou rodando Vicuna 30b quantizado. De novo, j√° vou explicar o que isso significa. Dizem que tem qualidade parecida com GPT 4 mas pra mim pareceu mais um GPT 3. As respostas que consigo no GPT 4 ainda s√£o mais completas do que nesse Vicuna.</p>
<p>Mas mesmo assim √© impressionante. Est√£o vendo? Estou conversando de boas. E n√£o est√° conectando com nenhum servi√ßo online de ningu√©m, nem da Microsoft, nem da OpenAI, nem do Google. Tudo rodando offline, local, dentro da minha m√°quina virtual. Vou repetir, porque quando postei sobre isso no Instagram, muita gente ficou confusa. Sim: d√° pra rodar um programa similar ao servi√ßo de ChatGPT da OpenAI num computador normal. E n√£o se trata de uma demonstra√ß√£o hello world, realmente funciona. N√£o precisa de um monte de servidores parrudos pra conseguir isso. U√©, mas eu achava que precisava ter o tamanho de uma Microsoft ou Google pra fazer isso, o que mudou?</p>
<p>A exig√™ncia de hardware depende da complexidade do modelo. Como falei, estou usando Vicuna de 30 bilh√µes de par√¢metros, mas existem modelos menores, como o pr√≥prio Vicuna de 7 bilh√µes de par√¢metros, ou a Ada da Microsoft, de s√≥ 350 milh√µes. Se o modelo for pequeno o suficiente, √© poss√≠vel at√© rodar num bom smartphone Android ou um Raspberry Pi com um upgrade de RAM. O tamanho do modelo √© um dos fatores que pode afetar a qualidade das respostas, portanto quanto menor o modelo, mais simples seriam as respostas. Simplifiquei sobre "tamanho", guardem essa informa√ß√£o que j√° vou explicar mais.</p>
<p>Deixa recapitular um pouco. O que diabos √© isso de modelo? Honestamente, eu mesmo n√£o sei dizer em todos os detalhes, pra isso precisaria ter estudo e treinamento em intelig√™ncia artificial, em particular redes neurais. Muita gente aprendeu isso em optativas ou inicia√ß√£o cient√≠fica na faculdade de ci√™ncias da computa√ß√£o. N√£o vou tentar dar explica√ß√£o acad√™mica, mas sim dar uma intui√ß√£o pra maioria de voc√™s conseguirem ter uma imagem na cabe√ßa. Acad√™micos, sejam compreensivos, e se quiserem complementar, sintam-se a vontade nos coment√°rios abaixo.</p>
<p>Pense em redes neurais como uma simula√ß√£o do aprendizado que acontece no nosso c√©rebro. Sabemos que temos neur√¥nios. Aprendizado e mem√≥ria acontecem quando temos sinapses, conex√µes desses neur√¥nios, ou comunica√ß√£o, ou melhor "ativa√ß√£o de um neur√¥nio", que √© como se ele escolhesse um caminho dentre muitos. Um neur√¥nio pode ter milhares de conex√µes, dizem que umas 7 mil. De novo, explica√ß√£o grosseira. Mas √© mais ou menos isso que temos em redes neurais. Assista os videos do canal 3Blue1Brown sobre redes neurais pra entender em mais detalhes.</p>
<p>No caso espec√≠fico de texto, poder√≠amos pensar que a forma de fazer computadores aprenderem a interpretar e gerar texto seria cadastrando regras gramaticais, ortogr√°ficas, vocabul√°rio, dicion√°rios, e assim ele conseguiria construir frases gramaticalmente corretas. Mais ou menos como voc√™ pensa que √© o jeito certo de aprender uma l√≠ngua nova como ingl√™s ou franc√™s num curso qualquer. Esse parece ser o jeito intuitivo, certo?</p>
<p>Mas se assistiu meu video de Como eu Aprendi Ingl√™s e a minha live com o Matt sobre aprender japon√™s, j√° sabemos que n√£o √© assim. N√£o se trata de decorar d√∫zias de regras. Nem no aprendizado em geral, nem em intelig√™ncia artificial. N√£o existem "regras" como um monte de "ifs". Pense por dois segundos: quando foi a √∫ltima vez que voc√™ escreveu um texto 100% gramaticalmente e formalmente correto? Concorda que um texto assim seria super estranho? Sem g√≠rias, sem maneirismos, sem coloquialismos, com palavras consideradas rebuscadas. Exatamente o que associamos com um rob√¥ falando.</p>
<p>J√° falei isso nesses outros videos, mas vou repetir: como voc√™ aprendeu portugu√™s? Foi lendo um livro do tamanho da B√≠blia, lotado de regras gramaticais? Quando tinha 1 ou 2 anos de idade? Como um beb√™ que nasceu nos Estados Unidos aprendeu ingl√™s? Como um beb√™ que nasceu na China aprendeu chin√™s? Nenhum deles usou nenhum livro, nenhum curso, nenhuma regra. Simplesmente passaram um temp√£o ouvindo os pais e pessoas ao redor e come√ßaram a repetir o que ouviam. Bem errado no come√ßo.</p>
<p>Todo mundo vai dando feedback. Quando o beb√™ tinha uma inten√ß√£o, sei l√°, dizer que est√° com fome. Ele tentava juntar palavras que j√° tinha ouvido antes e que parecia descrever o que queria. Se os adultos ao redor dessem comida, √© o feedback que o que falou parece que faz sentido. E assim ele vai associando as combina√ß√µes de palavras com comportamentos. Vai refinando seu aprendizado. Fazendo novas sinapses, novas conex√µes. Pouco a pouco melhorando a comunica√ß√£o e se fazendo entender melhor.&nbsp;</p>
<p>A grosso modo √© como seria o que chamamos de treinamento supervisionado, no mundo de intelig√™ncia artificial. N√≥s n√£o programamos regras gramaticais nem cadastramos palavras num banco de dados manualmente e ficamos fazendo "ifs" pra montar frases. Em vez disso come√ßamos com um corpo de dados gigante. Por exemplo, todos os artigos da Wikipedia, todos os c√≥digos abertos dispon√≠veis no GitHub, todos os papers acad√™micos dispon√≠veis publicamente, todos os livros digitalizados num Google Books. Bastante texto. Dezenas ou centenas de gigabytes de texto puro.</p>
<p>Pra entender isso, deixa eu fazer uma tangente e explicar um conceito relacionado que n√£o √©, em si s√≥, intelig√™ncia artificial, mas faz parte da mat√©ria. Na faculdade de ci√™ncia da computa√ß√£o, se aprende sobre processos estoc√°sticos, que estuda aleatoriedade, probabilidades, ou melhor, a evolu√ß√£o de um sistema ou fen√¥meno ao longo do tempo de forma probabil√≠stica. Ele descreve o comportamento de um sistema ou quantidades que mudam aleatoriamente ao longo do tempo. Em particular quero falar de Cadeias de Markov.</p>
<p>N√£o estou falando que o ChatGPT n√£o √© uma Cadeia de Markov, √© s√≥ pra ilustrar um ponto. Cadeias de Markov √© uma das formas de representar e analisar sequ√™ncias de eventos, ou estados, onde a probabilidade de transicionar de um estado pra outro depende somente do estado atual, √© um sistema sem mem√≥ria ou backtracking, sem considerar a sequ√™ncia de todos os estados anteriores, s√≥ o √∫ltimo. Em resumo √© um conjunto de estados e probabilidades de transi√ß√£o. Se pareceu grego, vamos ver um exemplo pr√°tico.</p>
<p>Digamos que em vez de ter gigabytes de textos como descrevi antes, nosso corpo de treinamento sejam s√≥ 3 frases em portugu√™s: "Eu gosto de comer ma√ß√£s.", da√≠ "Ela gosta de jogar t√™nis." e finalmente "Ele prefere ler livros.". Podemos construir um modelo baseado nessas frases, onde os estados s√£o palavras, ou tokens, e as transi√ß√µes entre estados representam a probabilidade de mover de um token pra outro. Vamos construir esse modelo simplificado.</p>
<p>Os tais estados podem ser s√≥ as palavras, tokenizadas ou quebradas a partir dessas frases, da√≠ ter√≠amos essa lista de palavras, "Eu", "gosto", "de" etc.&nbsp;</p>
<pre><code>1. Eu
2. gosto
3. de
4. comer
5. ma√ß√£s
6. Ela
7. gosta
8. jogar
9. t√™nis
10. Ele
11. prefere
12. ler
13. livros
</code></pre>
<p>As transi√ß√µes s√£o as probabilidades. Esses s√£o exemplos, mas digamos que a transi√ß√£o do token, ou estado "Eu" pro estado "gosto" √© probabilidade 1, ou seja, 100%. Mas a transi√ß√£o do estado "de" pra "comer" √© 0.5 ou 50% porque poderia ser pra "jogar" que √© 0.5 tamb√©m. Pra ficar claro, na primeira frase temos "de comer", mas na segunda frase tempos "de jogar", por isso a partir do token "de" temos duas possibilidades, 50% de chance pra cada.</p>
<p>Como temos poucas frases de treino, as transi√ß√µes s√£o quase 100% de uma palavra pra outra, porque esse modelo s√≥ conhece 3 frases. Num treinamento de verdade com gigabytes de textos, ter√≠amos trilh√µes de possibilidades diferentes e probabilidades pequenas e fracionadas, como 0.001234 bla bla.&nbsp;</p>
<p>Finalmente, digamos que come√ßamos a digitar um texto e queremos que esse modelo continue completando a frase pra gente. Podemos usar o modelo da cadeia de Markov pra prever o que seria a palavra mais prov√°vel baseado nas probabilidades de transi√ß√£o que vimos na lista anterior. Por exemplo, come√ßo digitando "Eu" e a probabilidade da pr√≥xima palavra ser "gosto" √© 100%, ent√£o √© isso que ele d√° de previs√£o. Se digitar "Ele", a probabilidade segundo a lista √© 100% pra "prefere".</p>
<pre><code>- De "Eu": gosto (1.0)
- De "gosto": de (1.0)
- De "de": comer (0.5), jogar (0.5)
- De "comer": ma√ß√£s (1.0)
- De "ma√ß√£s": Eu (1.0)
- De "Ela": gosta (1.0)
- De "gosta": de (1.0)
- De "de": jogar (0.5), ler (0.5)
- De "jogar": t√™nis (1.0)
- De "t√™nis": Ela (1.0)
- De "Ele": prefere (1.0)
- De "prefere": ler (1.0)
- De "ler": livros (1.0)
- De "livros": Ele (1.0)
</code></pre>
<p>Por causa de smartphones, todo mundo j√° viu isso em a√ß√£o de verdade. √â a funcionalidade de auto-corre√ß√£o que tem em todo teclado. Olhe neste exemplo, come√ßo digitando uma palavra e o teclado sozinho vai sugerindo a pr√≥xima palavra, e podemos s√≥ aceitar a sugest√£o. E ele vai sozinho completando a frase. Claro, se ficar fazendo s√≥ assim, a frase vai ficando meio sem sentido nenhum, mas ele consegue gerar uma frase que mais ou menos parece um humano que escreveu, n√£o acha?</p>
<p>Vou repetir: isso √© uma explica√ß√£o simplificada, tem v√°rias outras t√©cnicas em cima de cadeias de Markov, mesmo pra um tecladinho simples de iOS ou Android. Mas em linhas gerais, pense que em vez de 3 frases, o modelo desses teclados foi pr√©-treinado com milhares de frases. O modelo √© essa lista de combina√ß√µes de palavras e as probabilidade da pr√≥xima palavra, dada uma palavra anterior. Essas probabilidades √© o que chamamos de "pesos". E mais importante: em nenhum momento usamos quaisquer regras hard-coded de gram√°tica ou ortografia ou ifs ou templates. Ele vai completando a frase puramente usando esses pesos, aprendidos no treinamento, nada mais.</p>
<p>Agora vamos voltar pro ChatGPT ou pra minha vers√£o local do text-generation com Vicuna. Voc√™s nunca acharam estranho que as respostas sempre demoram e ele vai escrevendo uma palavra de cada vez? Alguns poderiam achar que √© s√≥ uma anima√ß√£o arbitr√°ria pra fazer parecer que o ChatGPT √© uma pessoa digitando. Mas deixa eu rodar uma vers√£o fora da interface Web, na linha de comando mesmo. Prestem aten√ß√£o.</p>
<p>(... screencast command line fastchat ...)</p>
<p>Pra ficar mais claro, vou colocar do lado o monitoramento da minha GPU, a ferramenta da nvidia chamado "nvidia-smi" que faz o monitoramento dos recursos sendo usados na GPU. Notem que durante a composi√ß√£o da resposta, a GPU est√° em uso constante, processando alguma coisa, sem parar. N√£o sei porque usa s√≥ 50% do processamento dispon√≠vel, mas de qualquer forma, a resposta n√£o √© instant√¢nea. N√£o √© uma anima√ß√£o feita s√≥ pra fazer gra√ßa, √© que ele demora isso mesmo palavra a palavra. Cada palavra nova que vai aparecendo est√° gastando processamento da GPU. Se levou 5 segundos pra dar a resposta, foi 5 segundos que a minha GPU ficou processando sem parar.</p>
<p>Conseguem ver as similaridades entre o auto-corretor do seu tecladinho de celular e o processo de resposta do ChatGPT? Internamente ele est√° fazendo algo similar a procurar probabilidades na cadeia de Markov. Mas claro, o modelo de GPT, LLaMA, Vicuna, Bard, e outros, √© mais complicado que um mero modelo de Markov. Vamos entender.</p>
<p>Quando as primeiras not√≠cias anunciando o ChatGPT sa√≠ram, gerou muita confus√£o, que persiste at√© hoje. Por exemplo, quando o ChatGPT 4 foi anunciado, eles mencionam, "uau, o ChatGPT 3.5 tinha 175 bilh√µes de par√¢metros mas o ChatGPT 4 tem incr√≠veis 100 a 170 TRILH√ïES de par√¢metros". A √∫nica coisa que os jornalistas e voc√™s entenderam foi "uau, bilh√µes pra trilh√µes de ... whatever ... trilh√µes √© absurdamente maior que bilh√µes, ent√£o o GPT novo √© milh√µes de vezes melhor e o GPT 5 vai ser mais milh√µes de vezes melhor". E √© assim que todo mundo mente e se auto-engana com n√∫meros, sem saber o que significa.</p>
<p>Esse meu Vicuna, rodando localmente na minha m√°quina, tem meros 30 bilh√µes de par√¢metros. Puuuts, quer dizer que ele deve ser pelo menos 5 vezes pior que o ChatGPT antigo, n√©? Nem chega aos p√©s do GPT 4. S√≥ que se olhar alguns artigos que descrevem o Vicuna menor, o de 13 bilh√µes de par√¢metros, muitos declaram que rodando diversos testes, os mesmos que a pr√≥pria OpenAI usa pra avaliar o GPT deles, dizem que o Vicuna 13B chega a 90% do n√≠vel de qualidade do GPT 4 ou Google Bard. E o Vicuna, sendo derivado do LLaMA do Facebook, nesses mesmos testes, ultrapassa o LLaMA original. Como pode isso?</p>
<p>Antes de mais nada, o que diabos s√£o esses tais par√¢metros? No contexto de machine learning, par√¢metros se referem aos pesos que o modelo aprende durante o processo de treinamento. De forma simplificada e grosseira, lembra a lista de probabilidades de transi√ß√£o de estados da cadeia de Markov que mostrei no exemplo? Aquilo poder√≠amos chamar de par√¢metros. No nosso treinamento com s√≥ 3 frases, gerou um modelo de 16 par√¢metros. Pense numa lista como aquela s√≥ que bilh√µes de linhas. 13 bilh√µes ou 30 bilh√µes no caso do Vicuna, ou 170 trilh√µes no caso do ChatGPT 4.</p>
<p>E lembra como no exemplo, dado uma palavra, podemos ir na lista de probabilidades e ver qual poderia ser a pr√≥xima palavra? A grosso modo, √© como GPT ou Vicuna fazem. S√≥ que em vez de considerar s√≥ a palavra anterior e procurar a pr√≥xima, ele v√™ quais foram as palavras anteriores e leva todas em considera√ß√£o pra tentar prever a pr√≥xima palavra. Lembra como minha GPU fica processando sem parar enquanto monta a resposta? √â isso que est√° fazendo: pesquisando no modelo pela pr√≥xima palavra, mas considerando parte ou todo o texto anterior, incluindo as palavras que ele mesmo sugeriu, vai ficando cada vez mais pesado. Por isso demora.</p>
<p>Antes que o pessoal acad√™mico me crucifique, √© melhor eu me corrigir aqui. Eu repeti v√°rias vezes "a grosso modo", "a grosso modo", porque o modelo do GPT n√£o s√£o probabilidades de pares de palavras, daquele jeito bonitinho como no exemplo. Intuitivamente, poder√≠amos pensar que quando se quebra um texto longo, ter√≠amos conjuntos de "palavras". Mas vamos recordar a met√°fora do beb√™ aprendendo?</p>
<p>Todo mundo j√° deve ter percebido que um beb√™ n√£o ouve um adulto falar uma palavra e sai repetindo bonitinho igualzinho, certo? Parte da divers√£o √© justamente ver ele falando errado no come√ßo e ir ajustando. O beb√™ tenta reproduzir o que ele "acha" que ouviu. Da√≠ voc√™ d√° o feedback negativo e ele vai tentando de outras formas, at√© uma hora acertar. No mundo de machine learning e deep learning, podemos usar isso como met√°fora. No treinamento ele n√£o isola palavras, isola "patterns" de funcionalidades, ou features, do material de treinamento.&nbsp;</p>
<p>Fora de IA, no mundo de full-text search, ou em processamento de linguagem natural, temos ferramentas como Elasticsearch ou Apache Solr, que expliquei no epis√≥dio do Twitter. Eles n√£o quebram os textos indexando palavras, mas sim grams. Quem j√° leu a documenta√ß√£o deve ter visto o termo n-gram, que s√£o sequ√™ncias de "n" itens ou tokens. Pode ser uma palavra inteira, mas pode ser s√≥ parte de uma palavra. Uma sequ√™ncia de s√≥ uma letra seria um unigram, duas letras um bigram, tr√™s letras, trigram e assim por diante.</p>
<p>Quando indexamos texto, √© mais √∫til indexar n-grams do que palavras inteiras, √© o que nos permite fazer coisas como achar palavras "parecidas" ou que "soam" parecido, que tem mesmo sufixo ou mesmo prefixo, como conjuga√ß√£o de verbos. Mesma coisa com o teclado de auto-corre√ß√£o, ele indexa n-grams. Por isso voc√™ digita a pesquisa tudo errado num Google, mas ele diz no resultado "voc√™ quis dizer X". O mundo de indexa√ß√£o de textos √© todo baseado no conceito de n-grams. Vale a pena estudar isso depois.</p>
<p>Quer dizer que o tal modelo do GPT s√£o pesos em cima de n-grams? Infelizmente tamb√©m n√£o √© assim f√°cil. Eu mencionei n-grams s√≥ pra explicar como podemos dividir palavras de outras formas n√£o intuitivas. Agora, o problema com sinapses no nosso c√©rebro ou redes neurais √© que os pesos n√£o s√£o aplicados em cima de id√©ias discretas, como palavras ou letras ou imagens inteiras. De novo, pra entender tecnicamente como redes neurais funcionam, procure material de universidades como do MIT, Stanford ou lugares assim, e de novo, acad√™micos, peguem leve comigo.</p>
<p>No fim do dia, um modelo √© como se fosse um banco de dados, contendo probabilidades ou pesos de um elemento pra outro elemento. Parecido com o exemplo da auto-corre√ß√£o. Mas o principal √© que n√£o s√£o necessariamente palavras, n√£o s√£o tamb√©m s√≥ n-grams, pode ser qualquer tipo de pattern que foi identificado no aprendizado. Pode ser uma letra pra uma palavra. Pode ser um bigram pra um trigram. Pode ser muitas coisas. Por exemplo, poderia ser "ef" pra "yw" probabilidade 0.01234. O que isso significa?</p>
<p>Isoladamente n√£o significa absolutamente nada. Ela s√≥ vai fazer sentido dentro de uma rede de pesos. A probabilidade final √© uma composi√ß√£o de m√∫ltiplos passos pelos n√≥s dessa rede. O modelo n√£o √© uma lista, provavelmente √© mais como um espa√ßo vetorial multi-dimensional, tipo matrizes de matrizes. Eu expliquei espa√ßos vetoriais no epis√≥dio do Twitter tamb√©m. Similaridade de Cosseno, √Ålgebra Linear, lembram? De novo, pra visualizar, n√£o pense num modelo como sendo uma lista, como um array simples. Pense como um array de arrays, de arrays. Multi-dimensional.</p>
<p>Se multi-dimensional n√£o √© intuitivo pra voc√™s, pense num elemento simples, tipo uma vari√°vel de tipo inteiro. Isso √© o que chamamos de valor escalar, com zero dimens√µes. Representa um √∫nico valor. Agora, um array de escalares, como um array de inteiros. Isso √© vetor, uma lista de uma √∫nica dimens√£o. Em seguida, em vez de escalares, se eu fizer um array de arrays, onde cada elemento do array √© outro array, e esse array for unidimensional, agora temos uma matriz, que √© um ret√¢ngulo, ou uma grade de valores escalares.</p>
<p>Finalmente, e se esse array interno tamb√©m tiver arrays como elementos? Agora temos um array de arrays de arrays, tridimensional. E podemos ir adiante, esse √∫ltimo array tamb√©m pode ter arrays de elementos, que tem arrays de elementos, que tem arrays de elementos, a√≠ temos matrizes multi-dimensionais ou mais corretamente, tensores de alto ordenamento ou tensores n-dimensionais.</p>
<p>Ali√°s, tudo isso que eu expliquei s√£o tensors, sabe, do tal Tensorflow do Google? Um escalar √© um tensor de zero dimens√µes, um vetor √© um tensor de uma dimens√£o, uma matriz √© um tensor de duas dimens√µes e acima disso √© um high-order tensor ou n-dimensional tensor. Ent√£o, voltando pro tal modelo do GPT ou Vicuna, n√£o pense como no exemplo simples do auto-corretor, que foi somente um vetor, um array unidimensional de pesos. Pense que esses pesos est√£o estruturados em tensores n-dimensionais.</p>
<p>Todos esses conceitos que vim explicando n√£o s√£o a ponta do iceberg. S√£o a raspa da ponta do iceberg. Pode parecer que quero dizer que um ChatGPT n√£o √© mais que uma cadeia de Markov, s√≥ que maior. N√£o √© isso, √© s√≥ uma met√°fora pra explica√ß√£o. Deixa eu tentar explicar qual foi a tal "revolu√ß√£o" que permitiu o salto de um mero auto-corretor pra um ChatGPT. Mas entenda: redes neurais e deep learning existem faz d√©cadas. A comunidade de ci√™ncias da computa√ß√£o vem fazendo descobertas e refinando as tecnologias faz muito tempo. N√£o foi do nada que isso apareceu.</p>
<p>Seguindo o exemplo do auto-corretor, deve ser f√°cil de perceber um dos problemas: ele s√≥ usa a palavra anterior pra tentar descobrir qual a pr√≥xima palavra. Por isso muito rapidamente a frase fica sem sentido. D√° impress√£o que foi um humano que escreveu, mas um humano bem burro. √â diferente de um punhado de palavras completamente aleat√≥rias, mas as frases que gera, s√£o bem in√∫teis. Quanto maior tentar fazer a frase, pior vai ficar.</p>
<p>Claro, o certo √© que a pr√≥xima palavra leve em considera√ß√£o n√£o s√≥ a palavra anterior, mas todas as palavras anteriores, pra manter a coer√™ncia. √â isso que poder√≠amos chamar de backtracking ou recurrency. Isso tem que ser levado em conta durante o treinamento. N√£o basta quebrar o texto em palavras e s√≥ fazer o peso da palavra seguinte. Tem que ser o peso da palavra seguinte dado as palavras anteriores. √â a√≠ que nasce coisas como RNN ou Recurrent Neural Networks.</p>
<p>RNNs foram desenhados pra lidar com sequ√™ncias de tamanhos variados, como senten√ßas, dados de s√©ries de tempo, sinais de discurso. Eles conseguem processar inputs, como texto, um passo de cada vez e ao mesmo tempo mantendo um estado interno escondido que mant√©m informa√ß√µes dos passos anteriores. Ou seja, ele mant√©m mem√≥ria durante o aprendizado. √â como a gente aprende tamb√©m.</p>
<p>Uma coisa √© aprender, por exemplo, a palavra "foda". Dependendo do contexto pode significar coisas diferentes. Pode ser que signifique "puts, que foda esse macbook novo" ou seja, positivo. Ou pode ser "puts, que trampo foda de dif√≠cil", ou seja, negativo, e v√°rias outras varia√ß√µes. Precisamos de contexto, e contexto precisa de mem√≥ria pra gerar pesos diferentes pra contextos diferentes. Consegue imaginar o trampo de processar pensando dessa forma?</p>
<p>RNNs usam t√©cnicas como BPTT ou Backpropagation Through Time, literalmente propaga√ß√£o reversa atrav√©s do tempo, pra computar gradientes e atualizar os par√¢metros do modelo. Ent√£o n√£o √© um processamento que voc√™ pega um texto, l√™ s√≥ uma vez do come√ßo ao fim e j√° gera um modelo, escrito linearmente do come√ßo ao fim. Tem que ficar voltando pra tr√°s no modelo pra ajustar. E j√° que √© pra dificultar, em todo paper de IA por a√≠ vamos esbarrar nesse termo "gradiente". Deixa eu resumir.</p>
<p>Gradiente se refere √† derivada da loss function, fun√ß√£o de perda, ou de custo. Puts Akita, eu nunca vou usar C√°lculo na vida, √© perda de tempo. Bom, eis um pequeno exemplo. Pra que serve derivada? Ela serve pra medir a taxa de mudan√ßa de uma fun√ß√£o. Em resumo, a derivada nos diz como o resultado de uma fun√ß√£o muda √† medida que fazemos pequenas modifica√ß√µes nos valores de entrada. Lembra de f√≠sica cinem√°tica no colegial? F√≥rmula pra saber o espa√ßo ao longo do tempo? F√≥rmula de Velocidade ao longo do tempo? A de velocidade √© derivada da f√≥rmula de espa√ßo, porque velocidade √© a taxa de mudan√ßa da f√≥rmula de espa√ßo ao longo do tempo. Acelera√ß√£o √© a taxa de mudan√ßa da f√≥rmula de velocidade.&nbsp;</p>
<p>Em particular, gradientes em c√°lculo de m√∫ltiplas vari√°veis √© um vetor que aponta na dire√ß√£o da ascendente mais √≠ngreme da fun√ß√£o. Isso √© super importante em otimiza√ß√£o de algoritmos, como gradient descent, ou descida de gradiente, que iterativamente atualiza os par√¢metros pra encontrar a fun√ß√£o de custo m√≠nimo. Dado que gradientes nos ajudam a entender a taxa de mudan√ßa de resultados de uma fun√ß√£o, podemos usar pra encontrar os pontos de m√°xima e m√≠nima, pra otimiza√ß√£o. E esse conceito √© importante em otimiza√ß√£o de machine learning.</p>
<p>Em Machine Learning tem um tro√ßo que chamam de "loss function" tamb√©m conhecido como fun√ß√£o de custo, que √© uma fun√ß√£o matem√°tica que quantifica a discrep√¢ncia entre resultados previstos de um modelo com os valores de verdade. Lembrando, uma das formas de treinar √© dar um monte de dados de treinamento, da√≠ pedir pro modelo devolver respostas a v√°rias perguntas e ver se as respostas est√£o corretas. Justamente pra calibrar o aprendizado. Lembra do beb√™ aprendendo a falar e olhando pra nossa cara pra ver se a gente entendeu? Tipo isso.</p>
<p>O objetivo do tal treinamento √© ver qu√£o bem um modelo performa determinadas tarefas. A escolha de qual fun√ß√£o de custo usar depende do problema que queremos resolver, como regress√£o, classifica√ß√£o, gera√ß√£o de sequ√™ncias. Por exemplo, em tarefas de regress√£o, uma fun√ß√£o de custo popular √© o MSE ou mean squared error, erro quadrado mediano, ou o MAE que √© mean absolute error, erro absoluto mediano. Em tarefas de classifica√ß√£o tem custo de entropia cruzada e assim por diante. O importante √© entender que treinamento n√£o √© um tro√ßo aleat√≥rio. Tem fun√ß√µes de m√©trica e controle pra calibrar e otimizar.</p>
<p>Durante o treinamento, os par√¢metros do modelo s√£o ajustados pra minimizar essa fun√ß√£o de custo usando algoritmos de otimiza√ß√£o como o "gradient descent". Agora voc√™s entendem uma das formas que c√°lculo influencia a qualidade do treinamento de um modelo de rede neural. Pra hoje, pense em rede neural como uma caixa preta, que nem uma fun√ß√£o que voc√™ programa na sua linguagem de programa√ß√£o. Ela tem vari√°veis de entrada e algum retorno. A entrada seria as tais toneladas de textos pro treinamento. Da√≠ no meio, nessa caixa preta, esses dados s√£o processados de alguma forma, e o retorno vai ser o tal modelo multi-dimensional.</p>
<p>Essa etapa no meio √© o processamento dos textos e materiais de treinamento que passamos. Processos como tokeniza√ß√£o que √© quebrar o texto em listas de sequ√™ncias de palavras. S√£o uma s√©rie de transforma√ß√µes pra massagear esses dados em diversas camadas escondidas. Essas transforma√ß√µes envolvem c√°lculos, por exemplo, soma ponderada. Cada neur√¥nio de uma camada escondida recebe inputs de uma camada anterior. A cada input √© assinalado um peso. O neur√¥nio computa a soma ponderada dessas entradas, onde os pesos determinam a signific√¢ncia da contribui√ß√£o de cada input pra sa√≠da do neur√¥nio.</p>
<p>Da√≠ a soma ponderada pode ser passada pra uma fun√ß√£o de ativa√ß√£o, que introduz n√£o-linearidade e determina a sa√≠da da fun√ß√£o. N√£o linearidade e sistemas complexos √© um assunto gigantesco, nem vou tentar explicar. Mas pra ter intui√ß√£o pense assim: voc√™ t√° acostumado a pensar em sistemas lineares. Por exemplo, se 1 litro de gasolina d√° pra andar 15 quil√¥metros, ent√£o 10 litros de gasolina vai dar 150 quil√¥metros. Mas n√£o-linearidade √© que nem tentar prever o tempo.&nbsp;</p>
<p>S√≥ porque temos 80% de humidade no ar e no passado vimos que isso indicava uma chuva de, sei l√°, 20 mil√≠metros. N√£o quer dizer que se eu medir hoje 80% vai dar os mesmos 20 mil√≠metros. Pode ser 40. Pode ser zero. Tem uma rede de outras vari√°veis, algumas mensur√°veis, algumas desconhecidas, uma influenciando a outra. Vari√°veis min√∫sculas podem amplificar resultados completamente inesperados.</p>
<p>√â o famoso caso da Borboleta de Lorenz. Aquela hist√≥ria que uma borboleta bate as asas no Brasil e tem um tsunami no Jap√£o. N√£o foi a borboleta que causou o tsunami, n√£o √© linear, n√£o tem causalidade direta. Mas quer dizer que essa min√∫scula contribui√ß√£o, somado a milhares de outras, "pode" ter causado o tsunami.&nbsp;</p>
<p>Depois parem pra ler sobre Teoria do Caos, √© fascinante, e o mundo real √© cheio de efeitos&nbsp;n√£o-lineares. E levamos isso em conta em redes neurais. Nosso c√©rebro tem aprendizado n√£o-linear, e √© o que tentamos simular com redes neurais. Agora, Deep Learning, como o pr√≥prio nome diz √© aprendizado profundo, e profundidade se refere a v√°rias camadas de aprendizado. Aquela fun√ß√£o caixa preta que eu mencionei? Imagine v√°rias delas em s√©rie, uma chamando a outra, v√°rias camadas de profundidade. L√≥gico, explica√ß√£o simplificada, mas s√≥ pra dar uma no√ß√£o.</p>
<p>Enfim, a parte importante √© que processar texto em deep learning usando t√©cnicas como RNN e BPTT seria absurdamente caro, pra manter toda a mem√≥ria e fazer todo esse backtracking na for√ßa bruta. √â a√≠ que entra o famoso paper do Google, "Attention is All You Need". Literalmente "Aten√ß√£o √© Tudo que Voc√™ Precisa", publicado por Vaswani e equipe em 2017. √â o paper que introduz a arquitetura de Transformers, os famosos transformadores que permitiram esta gera√ß√£o de LLMs como GPT.</p>
<p>Em pouqu√≠ssimas palavras, ele introduz o mecanismo de self-attention, ou auto-aten√ß√£o, tamb√©m conhecido como aten√ß√£o escalada de produto escalar. Eu expliquei produto escalar no contexto de espa√ßos vetoriais no epis√≥dio do Twitter. N√£o vou explicar de novo. Mas esse mecanismo permite o modelo pesar a import√¢ncia de diferentes posi√ß√µes na sequ√™ncia de entrada, possibilitando capturar efetivamente as depend√™ncias longas. Eu sei, √© dif√≠cil de entender isso, e tamb√©m de explicar. Mas lembra como RNN precisa manter um estado em mem√≥ria pra lembrar o contexto? Self-attention √© uma otimiza√ß√£o disso.</p>
<p>Em vez de ser recurrent neural network, ele passa a poder usar feed forward neural network. Da forma como eu entendo, em vez de um processo onde voc√™ d√° um passo pra tr√°s antes de poder dar um passo pra frente, agora √© s√≥ passos pra frente, feed forward. O que possibilita isso √© o tal mecanismo de auto-aten√ß√£o. Elimina a necessidade de recorr√™ncia ou convolu√ß√£o. E ainda permite paralelizar o processamento. Antes, como o passo seguinte dependia do passo anterior, tinha que ser feito em s√©rie, em sequ√™ncia linear. Parte da dificuldade de conseguir rodar coisas em paralelo √© eliminar as depend√™ncias que amarram o passo seguinte com o passo anterior. Isso vale n√£o s√≥ pra IA mas qualquer coisa.</p>
<p>Tornando o processo feed forward, evitando convolu√ß√£o, podemos paralelizar o processamento. O que levaria, chutando, um ano pra treinar, poderia ser feito em um m√™s. O importante √© entender que essa arquitetura de transformers √© uma otimiza√ß√£o massiva. √â mais ou menos o tipo de impacto que voc√™ v√™ num desenvolvimento web comum quando coloca um √≠ndice numa tabela gigante, ou quando coloca um cache na frente do banco de dados e ganha 5x ou 10x a performance. Independente de como funciona no detalhe, o importante √© entender que foi um salto grande.&nbsp;</p>
<p>Toda hora eu fico falando que os acad√™micos v√£o me matar vendo essas minhas explica√ß√µes grosseiras, mas eu mesmo fico do√≠do de ficar toda hora falando "a grosso modo", "simplificando", "em met√°fora", porque cada par√°grafo que falei at√© agora s√£o d√∫zias de papers e formalidades matem√°ticas. Estou tentando trazer um pouco desse vocabul√°rio, pra voc√™s entenderem que n√£o √© um chute do nada, mas tamb√©m reduzir em poucas palavras que ajudem a dar uma intui√ß√£o. Pra maioria de n√≥s, os detalhezinhos n√£o importam tanto. Tem mais valor ter a no√ß√£o desse processo, em linhas gerais, pra entender que n√£o √© m√°gica. Principalmente: qual o limite dessa m√°gica.</p>
<p>Mas com tudo isso que falei, vamos tentar entender o que √© o ChatGPT ent√£o. Como √© um projeto propriet√°rio, fechado e secreto da OpenAI, temos que acreditar nas informa√ß√µes que eles disponibilizaram. Ent√£o sempre leiam isso com v√°rios quilos de sal. Isso dito, parece que o treinamento foi baseado num corpo de aproximadamente 570 gigabytes de texto. Quais textos exatamente? N√£o sabemos, mas eles mencionam Wikipedia, artigos de pesquisa e papers, websites e outras formas de conte√∫do escrito na web, com um limite at√© 2021. Isso √© arbitr√°rio.</p>
<p>Pessoalmente, achei pouco texto, eu teria chutado mais. Mas 570 gigabytes s√≥ de texto puro √© bastante coisa na real. Por exemplo, a Wikipedia inteira d√° um total de 21 gigabytes, e isso eu acho que √© contando com o HTML que monta as p√°ginas. Se filtrar e limpar s√≥ os textos puros vai ser bem menos. Mas digamos que seja 21 gigabytes. Precisaria de mais de 30 Wikipedias inteiras pra completar os 570 gigabytes de dados de treino. √â um volume respeit√°vel.</p>
<p>Esse tanto de texto, dizem que deu um total de 300 bilh√µes de "palavras", entre aspas, mas acho que o jornalista entendeu errado. Um dicion√°rio de ingl√™s, como o Merriam Webster online n√£o tem meio milh√£o de palavras. Acho que s√£o 300 bilh√µes de tokens, que incluem palavras, mas tamb√©m n-grams como falei antes, e seja l√° quais outros patterns o deep learning identificou nesse material. Da√≠ passa por semanas fazendo todo o processo que falei de transforma√ß√£o. Esse processo, que levaria meses, agora parece que dura mais ou menos um m√™s rodando em n√£o sei quantos servidores usando hardwares como os agora famosos NVIDIA Grace-Hopper, os GH100.</p>
<p>Lembra que falei que, internamente, n√£o estamos lidando com valores escalares e sim com tensores multi-dimensionais? CPUs como um Intel ou AMD que roda no seu PC, mesmo os M1 ou M2 da Apple, s√£o chips com instru√ß√µes feitas pra c√°lculos em cima de valores escalares. Uma fun√ß√£o de soma pega dois valores inteiros de 64 bits e cospe um resultado inteiro de 64 bits. Eu explico como isso funciona nos epis√≥dios de emuladores como o do Super Mario, com processadores de 8-bits, depois d√™em uma olhada.</p>
<p>CPUs modernas incluem instru√ß√µes pra lidar com vetores, instru√ß√µes SIMD, Single Instruction, Multiple Data, literalmente uma instru√ß√£o pra m√∫ltiplos dados. Come√ßou com as instru√ß√µes MMX dos primeiros Pentium nos anos 90. Hoje temos conjuntos de instru√ß√µes como SSE4 ou AVX-512. Pra ter a intui√ß√£o, em vez de uma fun√ß√£o que recebe um inteiro, pense numa outra fun√ß√£o que recebe dois arrays, soma os dois arrays, e cospe um array resultante, tudo numa √∫nica instru√ß√£o.</p>
<p>GPUs, diferente de CPUs, n√£o tem capacidade de rodar qualquer programa gen√©rico. Lembram do meu epis√≥dio de Turing Complete? A grosso modo, uma m√°quina de Turing √© basicamente qualquer programa. Em particular, pra ser Turing Complete, pra ser um computador moderno, ele precisa ser capaz de rodar um programa que consegue simular ser um computador. Como exemplo mais √≥bvio pense uma m√°quina virtual. Ele nem precisa conseguir rodar na pr√°tica, mas tem que ter a capacidade te√≥rica. Num CPU ARM M2 da Apple, √© poss√≠vel simular uma CPU Intel usando o Rosetta. E esse programa de Intel roda achando que t√° num PC de verdade. Isso √© poss√≠vel porque um CPU ARM M2 √© Turing Complete.</p>
<p>J√° uma GPU n√£o tem essa capacidade. Diferente de CPUs, que s√£o gen√©ricos, e podem simular qualquer coisa, mesmo que lento, uma GPU √© um hardware especializado, pra executar um conjunto pequeno de tarefas bem definidas. Uma GPU n√£o consegue rodar um sistema operacional gen√©rico, nem simular ser outra GPU, tipo um AMD Radeon tentar simular ser um NVIDIA RTX. N√£o funciona assim. Quando existe camada de abstra√ß√£o, quem cuida disso √© a CPU. A GPU √© boa numa √∫nica coisa: fazer c√°lculos de vetores e matrizes.</p>
<p>Uma CPU Intel costuma ter sei l√°, 8, 16, 32 n√∫cleos com 2 threads cada, rodando a 4 ou 5 gigahertz hoje em dia. Mesmo chips de servidores como um Intel Xeon ou AMD EPIC n√£o tem muito mais que isso de cores. J√° uma GPU √© diferente. Uma nov√≠ssima RTX 4090 tem nada menos que 16 mil n√∫cleos pra shading de CUDA, 128 n√∫cleos pra ray tracing e nada menos que 512 n√∫cleos exclusivos s√≥ pra tensors. Uma GPU, diferente de uma CPU, tem milhares de n√∫cleos que rodam em clocks baixos como 1 gigahertz, pra fun√ß√µes altamente especializadas.</p>
<p>O que eu falei que √© o resultado do treinamento de deep learning? Um modelo de tensors n-dimensionais. O que foi feito pra calcular tensors multi-dimensionais? GPUs. Processar √°udio, processar video, processar pol√≠gonos ou voxels tridimensionais, √© tudo processamento de matrizes multi-dimensionais. Uma tela de computador ou do seu smartphone, como √© representado? Num monitor Full HD, √© um array de 1080 colunas, onde cada elemento √© um array de 1920 elementos pra cada linha. Se eu quiser escurecer essa imagem inteira? Pode ser uma substra√ß√£o em cada valor desses arrays. Fazemos isso adicionando, ou subtraindo uma matriz por outra matriz, que chamamos de um "filtro" ou kernel.</p>
<p>Numa CPU, voc√™ programaria como um loop nas colunas e outro loop nas linhas pra calcular a nova cor, pixel a pixel, seria 1920 vezes 1080 opera√ß√µes, ou mais de 2 milh√µes de opera√ß√µes. Numa GPU eu passo a matriz inteira e ele calcula tudo numa √∫nica opera√ß√£o. De novo, n√£o vou conseguir entrar em detalhes, mas essa √© a diferen√ßa fundamental.</p>
<p>De curiosidade, um dos maiores problemas dessa arquitetura de CPU controlando GPU √© o compatilhamento de mem√≥ria. Em PCs modernos a CPU tem um conjunto de RAM e a GPU tem um conjunto de VRAM separados. A CPU prepara os dados e tem que mandar pra GPU processar. Da√≠ uma vez calculado, a CPU precisa puxar o resultado de volta pra pr√≥pria RAM. No frigir dos ovos, essa comunica√ß√£o √© um gargalo.</p>
<p>N√£o √© raro vermos jogos, por exemplo, que perde frames mesmo a GPU n√£o estando em 100%, mas se olhar a CPU, ela que t√° em 100%, ent√£o vira um gargalo e a GPU fica um tempo parado esperando. Por isso desde a nona gera√ß√£o de consoles de videogames como PS5 e Xbox Series X se falou tanto em loads instant√¢neos e tecnologias de melhorar esse gargalo, como o Microsoft DirectStorage.</p>
<p>Tamb√©m √© por isso que a estrat√©gia da Apple com os chips M1 e M2 √© ser um SoC ou System on a Chip; um √∫nico chip que embute CPU, GPU e RAM tudo junto, pra minimizar ao m√°ximo esse gargalo. Juntar tudo no mesmo lugar garante uso mais eficiente de mem√≥ria e caminho mais curto de comunica√ß√£o, ajudando a evitar gargalos.</p>
<p>Na velocidade que estamos hoje, a dist√¢ncia da sua CPU Intel pros pentes de RAM √© gigante se comparado a soldar tudo junto no mesmo chip como a Apple faz. √â um saco porque n√£o d√° pra aumentar RAM depois, mas a raz√£o n√£o √© porque eles s√£o uma corpora√ß√£o querendo arrancar mais dinheiro de voc√™s, mas sim porque tirar esse gargalo faz muita diferen√ßa.</p>
<p>A mesma coisa acontece na solu√ß√£o pra data centers da Nvidia, a tal arquitetura Grace-Hopper que eu falei, come√ßa com um superchip Grace-Grace, tanto Intel quanto ARM, que eles mesmos desenvolveram, num √∫nico pacote com NVLink que √© um barramento de alt√≠ssima velocidade entre eles, e a alternativa Grace-Hopper que √© outro superchip que junta uma CPU Grace com uma GPU <code>H100</code> Hopper.</p>
<p>S√£o solu√ß√µes que juntam todos eses chips junto com meio terabyte de mem√≥ria RAM LPDDR5 de 32 canais. Estamos falando de 96 n√∫cleos de 3 nan√¥metros. √â um monstro. √â esse o produto que tem feito as a√ß√µes da NVIDIA disparar, porque eles encaixam perfeitamente pra acelerar processamento de transformers. Meu PC n√£o √© "parrudo", esse da NVIDIA sim, √© a verdadeira defini√ß√£o de "parrudo", o atual estado da arte em 2023.</p>
<p>√â com servidores desse tipo, n√£o sei quantos, que se pega meio terabyte de dados, quebramos em 300 bilh√µes de tokens, e no final a OpenAI consegue gerar um modelo de GPT 4.0 com os tais 170 trilh√µes de par√¢metros. Conseguem entender melhor agora essa frase? Da√≠ a m√≠dia e os jornalistas ficam assustados e noticiam como o GPT 4 se iguala ao c√©rebro humano, que tem 100 trilh√µes em sinapses. Lembram? Sinapses mais ou menos s√£o os pesos ou par√¢metros entre neur√¥nios. Agora que entendemos mais ou menos o que s√£o esses par√¢metros, vamos discutir a premissa errada: par√¢metros n√£o s√£o equivalentes a sinapses do c√©rebro humano.</p>
<p>Quando se joga n√∫meros arbitr√°rios assim no t√≠tulo de uma mat√©ria, todo mundo fica empolgado. Vamos entender o erro. Pra come√ßar, nosso c√©rebro, em m√©dia, tem uns 100 bilh√µes de neur√¥nios. De novo, eu n√£o sou um neurologista, ent√£o j√° assuma que minha explica√ß√£o vai ser simplificada e de alto n√≠vel. Em pesquisa de IA, tentamos igualar neur√¥nios biol√≥gicos com neur√¥nios digitais numa rede neural, e falamos em bits, como num computador. Mas pra come√ßar, neur√¥nios n√£o s√£o exatamente bin√°rios assim. Um √∫nico neur√¥nio √© capaz de lidar com m√∫ltiplos sinais e conex√µes. Em termos de sinapse pode ter at√© umas 7 mil.</p>
<p>Isso acho que seria m√°ximo, mas em m√©dia o c√©rebro √© capaz de at√© uns 600 trilh√µes de sinapses. N√£o sei porque, dependendo de onde se pesquisa, falam em 100 trilh√µes, outros falam em 600 trilh√µes. De novo, precisa pesquisar um pouco mais a literatura de neurologia pra entender o que isso significa. Mas n√£o √© um n√∫mero absoluto. Tem v√°rios fatores. Doen√ßas como Alzeimer, por exemplo, afeta justamente a capacidade de fazer e manter sinapses.</p>
<p>Em crian√ßas, quando o c√©rebro ainda √© muito mais el√°stico e n√£o foi limitado pelo crescimento, o potencial √© de 1 quadrilh√£o de sinapses. √â um n√∫mero absurdo, mas mais importante, os 170 trilh√µes de par√¢metros do GPT 4 n√£o se equipara √† quantidade de sinapses que nosso c√©rebro √© capaz ainda. Portanto √© falso que o GPT 4 j√° se igualou ao c√©rebro humano em quantidade de sinapses.</p>
<p>A outra premissa que errada: um par√¢metro de modelo de GPT n√£o √© equivalente a uma sinapse do c√©rebro humano, nem de longe. Usamos vocabul√°rio neurol√≥gico pra simplificar a descri√ß√£o em termos de intelig√™ncia artificial, como redes "neurais". √â uma met√°fora. Em nenhum momento, nenhum cientista da computa√ß√£o vai te dizer que um neur√¥nio de rede neural √© id√™ntico ou sequer pr√≥ximo de um neur√¥nio biol√≥gico. √â s√≥ uma abstra√ß√£o.</p>
<p>E no caso de IA, par√¢metros de modelos de transformers, comparado com neur√¥nios do c√©rebro. Vamos voltar ao meu Vicuna rodando localmente na minha m√°quina. Lembram da afirma√ß√£o do povo que fez testes e otimizou esse modelo? Um modelo Vicuna de 13 bilh√µes de par√¢metros, em muitos casos, chega at√© 90% da qualidade de respostas de um ChatGPT 4.0 de 170 trilh√µes de par√¢metros. Como isso √© poss√≠vel?</p>
<p>E por isso mencionei n√£o-linearidade e Teoria do Caos. Um √∫nico par√¢metro isolado, se tentar ler e interpretar, n√£o tem como inferir nada. S√≥ funciona se estiver combinado com v√°rios outros par√¢metros, numa rede. O resultado final depende da intera√ß√£o de m√∫ltiplos par√¢metros, e por isso se gasta processamento da GPU pra gerar uma resposta. Par√¢metros s√£o pesos, probabilidades. E tem v√°rias formas de otimizar isso. Por exemplo, probabilidades pra ter o m√°ximo de precis√£o podem ser valores escalares de tipo float de 32 bits. √â isso que se gera num modelo depois do treinamento.</p>
<p>Por√©m, pesquisas mostram que podemos truncar esses valores pra float-16 e a qualidade das respostas n√£o cai t√£o drasticamente. √â uma forma de otimiza√ß√£o. Simplificando, √© parecido com o conceito de m√∫sica em MP3, que dados das frequ√™ncias que o ouvido humano n√£o √© capaz de detectar s√£o cortados fora. Tecnicamente isso tira qualidade do √°udio, mas na pr√°tica a maioria dos humanos n√£o sente. Em termos de armazenamento, economizamos 10 vezes o espa√ßo fazendo isso.</p>
<p>Expliquei no epis√≥dio de 25 tera pra 5 gigas, onde pegamos uma imagem bruta em bitmap e reduzimos pra um JPEG. A qualidade cai, mas o olho humano sem treinamento, n√£o nota diferen√ßa t√£o grande assim. Otimiza√ß√µes e compress√£o s√£o formas de simplificar os dados, diminuir a qualidade, de forma que nossos sentidos, sem treinamento, n√£o sintam diferen√ßa significativa. Fazemos isso com modelos de IA tamb√©m.</p>
<p>Reduzir os valores de Float 32 pra Float 16 √© uma forma de quantiza√ß√£o. Existem v√°rias formas de quantiza√ß√£o que s√£o otimiza√ß√µes dos modelos, pra exigir menos processamento pra gerar respostas, sem danificar demais a qualidade. Isso ajuda a conseguir fazer um clone de ChatGPT como o Vicuna, rodar numa m√°quina caseira como a minha. Parece que minha RTX 3090 j√° √© quase topo de linha, mas n√£o. Por isso expliquei sobre a NVIDIA GH100 que √© o tipo de hardware necess√°rio pra rodar o ChatGPT de verdade.</p>
<p>Mas respondendo como um Vicuna de 13 bilh√µes de par√¢metros consegue competir com um GPT 4 de 170 trilh√µes √© porque al√©m de quantiza√ß√£o, os algoritmos de auto-aten√ß√£o tem evolu√≠do tamb√©m. Em auto-aten√ß√£o, que acontece no processo de treinamento, cada token numa sequ√™ncia precisa ser considerado com todos os outros tokens pra capturar depend√™ncias e relacionamentos. Tipicamente, auto-aten√ß√£o √© computado dentro de uma janela de contexto, onde cada token √© considerado com tokens vizinhos.</p>
<p>Agora tem uma variante chamada "auto-aten√ß√£o global" onde cada token √© considerado independente de posi√ß√£o ou dist√¢ncia, que permite o modelo capturar depend√™ncias num contexto mais global. Na pr√°tica √© assim: custa mais caro pra treinar, mas os par√¢metros resultantes no modelo tem mais qualidade. Ent√£o com menos par√¢metros conseguimos chegar em respostas de qualidade similar. Entenderam? A qualidade de um par√¢metro n√£o √© universal nem est√°tico, est√° mudando √† medida que aperfei√ßoamos os algoritmos de treinamento e estruturas de dados.</p>
<p>Redes neurais, mesmo deep learning com auto-aten√ß√£o global, ainda s√£o representa√ß√µes rudimentares e grosseiras do nosso c√©rebro. Pra um GPT ou Vicuna da vida, conseguir escrever um texto com estilo de Shakespeare, precisamos treinar com todos ou quase todos os textos do Shakespeare. Pra conseguir gerar uma m√∫sica parecida com Mozart, temos que dar o m√°ximo de composi√ß√µes de Mozart quanto poss√≠vel. O processo de treinamento vai encontrar patterns ou padr√µes e criar pesos pra eles, registrando no modelo. Mas isso ainda √© bem ruim se comparado ao c√©rebro humano.</p>
<p>Pense voc√™. Se estiver treinando em literatura ou m√∫sica. Mesmo n√£o lendo nem perto de todas as obras de Shakespeare, mesmo n√£o estudando nem de perto todas as composi√ß√µes do Mozart, rapidamente consegue come√ßar a copiar o estilo deles. Veja voc√™ como programador. N√£o precisou ler todos os c√≥digos j√° feitos em React pra come√ßar a escrever c√≥digos. Bastou uns 2 tutoriais. Nosso c√©rebro consegue aprender muito melhor que um transformer, com muito menos dados, e produzir resultados similares ou melhores dentro de um mesmo determinado assunto. IA hoje em dia ainda depende muito de for√ßa bruta.</p>
<p>Desde que o LLaMA foi lan√ßado em fevereiro de 2023, estamos s√≥ em junho e j√° temos dezenas de modelos diferentes, com v√°rios n√≠veis de quantidade de par√¢metros, caindo desde 65 bilh√µes at√© s√≥ 7 bilh√µes, com v√°rios tipos de otimiza√ß√£o como GPTQ pra quantiza√ß√£o, ou Float 16. E isso permite rodar algo parecido com esse meu Vicuna local, num Android ou at√© num Raspberry Pi.</p>
<p>√â o que eu acho ideal: um transformer rodando localmente, offline, sem compartilhar nenhum dado pessoal meu, nenhuma conversa, com nenhuma corpora√ß√£o por a√≠. Quanto menos dados meus eu tiver que dar pra algu√©m, melhor. Especialmente se esse algu√©m n√£o me paga por isso. Pelo contr√°rio, pra usar OpenAI eu preciso pagar assinatura. E sabe-se l√° o que fazem com minhas conversas.</p>
<p>Bacana, significa que se o jornaleiro fala que o GPT 4 √© pr√≥ximo j√° de um ser humano, e os nerdolas das ci√™ncias da computa√ß√£o j√° compactaram e tornaram eficientes at√© esse ponto do VIcuna. Ent√£o j√° era. T√° f√°cil fazer a Skynet n√©? Afinal, GPT 4 j√° consegue escrever c√≥digo de programa√ß√£o. Basta eu carregar o c√≥digo do GPT 4 e mandar ele melhorar o c√≥digo e gerar o GPT 5. Da√≠ eu pego o novo GPT 5 e fa√ßo ele fazer uma vers√£o melhor, o GPT 6, e assim sucessivamente, at√© eu ter o Gigachad GPT T-1000 Skynet que vai dominar o mundo, certo?</p>
<p>Errado. No final do dia, um GPT 5, 10, 20, continua n√£o sendo mais que um auto-corretor do seu teclado em vers√£o maior. Tirem da cabe√ßa a no√ß√£o de que √© uma "intelig√™ncia". Ela n√£o √© inteligente. Tentar definir intelig√™ncia √© um buraco de coelho profundo demais, vai ter gente masturbando filosofia aqui at√© o fim dos tempos e ningu√©m vai chegar numa conclus√£o. Vamos s√≥ assumir que at√© hoje n√£o temos uma defini√ß√£o exata de "intelig√™ncia humana". Na verdade, quando chamamos de "intelig√™ncia artificial" s√≥ quer dizer que os resultados, pra um ser humano, podem "parecer" com algo inteligente, mas n√£o que de fato "√©" inteligente. Entendem a diferen√ßa?</p>
<p>N√£o ter uma defini√ß√£o exata √© ruim, porque n√£o temos um plano exato de pra onde ir. Na neurologia de verdade, apesar dos avan√ßos, n√£o temos uma receita exata de como neur√¥nios e sinapses funcionam 100%. Temos uma boa id√©ia. Muita coisa ainda √© especulativo. Mas podemos dar alguns chutes educados baseado em tudo que falei at√© agora. E aqui vai ser minha opini√£o pessoal. Se algu√©m tiver pesquisas que discordam, sintam-se √† vontade pra linkar nos coment√°rios abaixo. Opini√£o por opini√£o, cada um pode ter a sua. A maioria parece estar pulando r√°pido demais pra religi√£o do AGI e eu vou ser advogado do diabo e dizer porque isso n√£o est√° nem perto de acontecer.</p>
<p>Voc√™s entenderam at√© aqui? Quando vamos na interface Web do ChatGPT ou Vicuna ou qualquer outro derivado e escrevemos o tal do prompt, a pergunta, damos uns segundos, e ele nos tr√°s uma resposta. Mas na realidade n√£o √© isso. O que vem na verdade √© uma continua√ß√£o do texto do prompt. Tem uma diferen√ßa importante aqui: ele n√£o est√° tentando te responder. Acontece que com os par√¢metros treinados do modelo, a probabilidade maior das pr√≥ximas palavras √© se parecer com uma resposta. Essencialmente o que est√° acontecendo √© similar ao auto-corretor do teclado do seu celular: dado o texto que acabou de digitar, quais palavras tem mais probabilidade de serem continua√ß√£o?</p>
<p>Entendam essa sutileza. Por isso falo que n√£o √© uma "intelig√™ncia". GPT ou Vicuna n√£o s√£o pessoas e nem entidades com cogni√ß√£o tentando se comunicar. √â meramente um completador de textos, ou mais tecnicamente, um transformer pr√©-treinado generativo, um gerador de texto. Uma pergunta, ou prompt, √© um texto que se digita na expectativa que o modelo consiga continuar completando. √â por isso que o texto da resposta vai aparecendo aos poucos, n√£o √© uma anima√ß√£o arbitr√°ria, √© igual voc√™ ficar clicando na pr√≥xima palavra sugerida pelo teclado.</p>
<p>Um dos par√¢metros que afeta essa continua√ß√£o se chama temperatura. N√≥s n√£o temos controle da temperatura do ChatGPT pela interface Web, mas no Bing da Microsoft tem esses controles de mais balanceado, mais preciso ou mais criativo. E no meu Vicuna tenho esse campo num√©rico. Novamente, do jeito que todo mundo escreve, parece que estamos configurando uma pessoa pra ser "mais criativa". Mas isso √© s√≥ parte do showzinho. Um transformer n√£o √© mais ou menos criativo, ele √© mais ou menos "aleat√≥rio".&nbsp;</p>
<p>Temperatura controla a aleatoriedade do complemento de texto sendo gerado, o que voc√™ chama de "resposta". O modelo assinala probabilidades pra cada poss√≠vel token, que s√£o candidatos pra ser a pr√≥xima palavra na sequ√™ncia. Alta temperatura, valores maiores do que "1.0", significa que o modelo assinala probabilidades similares a um conjunto maior de tokens. Se v√°rios tokens tem probabilidades parecidas, as respostas podem variar mais quando se repete a mesma pergunta. Quanto maior a temperatura mais voc√™ vai "achar" que ele t√° sendo mais criativo, mas tamb√©m aumenta a probabilidade dele come√ßar a dar respostas sem sentido.</p>
<p>Temperatura m√©dia, entre 0.5 a 1.0, √© a resposta "balanceada" do Bing. Mesma coisa que alta temperatura mas ele assinala probabilidades similares pra um conjunto menor de tokens, controlando um pouco mais o que se perceberia como "criatividade". Baixa temperatura, que √© abaixo de 0.1, faz o modelo assinalar probabilidades similares pra palavras que realmente tinham mais chances de ser o pr√≥ximo token. Isso faz a resposta parecer mais focada, determin√≠stica, previs√≠vel.</p>
<p>Respostas sem sentido, muitos chamam de alucina√ß√£o. Eu n√£o gosto desse termo, porque implica que se alucina√ß√£o √© tempor√°ria nas respostas, ent√£o no resto do tempo ele est√° sendo s√≥brio ou racional. E n√£o est√°. Todas as partes das respostas foram geradas mediante probabilidades do modelo. Eu s√≥ ajusto a quantidade de de aleatoriedade nos candidatos pra pr√≥xima palavra. Nada mais, nada menos. Ele nunca alucina, assim como nunca √© s√≥brio. Ele n√£o √© uma entidade consciente pra ser nenhuma das duas, √© s√≥ um programa obedecendo probabilidades armazenadas num modelo.</p>
<p>Entenda, no frigir dos ovos, "criatividade" no mundo de transformers, √© s√≥ uma m√©trica de aleatoriedade. N√£o tem nada a ver com criatividade humana. Assim como intelig√™ncia artificial n√£o tem nada a ver com cogni√ß√£o de verdade. Transformers, e todo tipo de machine learning ou deep learning, s√£o meros sacos de probabilidades. Eles n√£o tem de fato cogni√ß√£o pra pensar "huumm, os dados dizem que a probabilidade desse evento √© X, mas realmente faz sentido? tem alguma coisa que eu n√£o estou percebendo? Deixa eu parar pra pensar", que seria o que um ser humano inteligente consegue fazer. Transformers n√£o refletem, s√≥ cospem exatamente o que as probabilidade do treinamento do modelo dizem pra ele cuspir, e nada mais.</p>
<p>Quando um transformer consegue pegar uma equa√ß√£o e achar a resposta, ou pegar at√© a planilha de balan√ßo de uma empresa e dizer se est√° indo bem ou mau. Ela n√£o est√° sendo inteligente. Simplesmente existem probabilidades no modelo que levam √† resposta porque materiais que ele usou de treinamento tinham j√° a resolu√ß√£o de equa√ß√µes parecidas.</p>
<p>Da mesma forma que eu disse que n√£o existe um monte de "ifs" de regras gramaticais pra conseguir escrever textos, tamb√©m n√£o tem um monte de "ifs" de regras matem√°ticas pra fazer contas. Sempre volte √† imagem daquela lista de pares de palavras e probabilidades do exemplo do teclado com auto-corretor. Aquilo √© tudo que ele tem. Um conjunto gigante de probabilidades. Toda resposta que te d√°, por mais inteligente que pare√ßa, n√£o teve nenhum tipo de racioc√≠nio ou l√≥gica ou infer√™ncia, nem nada, s√≥ probabilidades.</p>
<p>Um texto gerado por um transformer √†s vezes pode parecer "simp√°tico". Se voc√™ for uma pessoa carente, vai parecer que o transformer responde se importando com voc√™. Mas nada disso √© intencional, √© voc√™ projetando nele o que gostaria que ele fosse. Todo mundo faz isso com animais de estima√ß√£o. Isso se chama "antropomorfismo". Voc√™ pode atribuir emo√ß√µes humanas pra animais ou objetos inanimados. Tem gente que jura que uma escultura sorri pra ele quando passa na frente. Obviamente n√£o.&nbsp;</p>
<p>Um exemplo simples disso s√£o nuvens no c√©u. Vira e mexe voc√™ olha pro c√©u e v√™ claramente uma escultura nas nuvens. Dependendo da sua inclina√ß√£o ideol√≥gica poderia pensar. "Uau, Deus realmente √© criativo, olha que obra maravilhosa nos c√©us que ele est√° me dando". Ou "Uau, a m√£e natureza √© especial, m√£e Gaia continua a demonstrar sua genialidade criativa at√© nos c√©us". Ou "Uau, a droga que eu acabei de tomar √© da hora ..." S√≥ esse √∫ltimo pode estar certo.</p>
<p>O fato √© que a nuvem em si n√£o est√° em formato de nada. Se passar um avi√£o por cima da mesma nuvem, n√£o vai ver nada, ou vai ver outra imagem. Da posi√ß√£o que voc√™ est√°, na sua cabe√ßa, suas sinapses pr√©-treinadas sugerem que voc√™ est√° enxergando a sillhueta de algum objeto ou animal que j√° viu antes. √â um efeito colateral da nossa cogni√ß√£o. Poder√≠amos chamar de bug. √â seu c√©rebro primitivo. O c√©rebro r√°pido, autom√°tico e meio burro.</p>
<p>Ningu√©m moldou essa nuvem, ela aleatoriamente acabou numa determinada posi√ß√£o, que parece ter um determinado formato. N√£o houve inten√ß√£o. Foi aleat√≥rio. Eu diria que a IA t√° pouco se fodendo pra voc√™, mas isso implicaria que ela tem consci√™ncia. Ela nem est√° se fodendo pra voc√™. Ela n√£o pensou em voc√™. Mesma coisa com um transformer. Ela n√£o tem consci√™ncia, ela simples √©. Uma mera ferramenta. Uma chave de fenda que sabe cuspir palavras segundo uma matriz de probabilidades. Nada mais, nada menos. Por acaso voc√™ est√° olhando pra chave de fenda e achando que est√° sorrindo pra voc√™. N√£o est√°. Isso diz mais sobre seu estado emocional do que sobre a ferramenta.</p>
<p>Significa que ela n√£o tem insights, n√£o tem momento "eureka" de descobrimento de coisas novas. Ela s√≥ √© capaz de sugerir uma palavra, depois das outras palavras que vieram antes, seguindo uma tabela de probabilidades que vieram do treinamento feito com gigabytes de texto. De vez em quando, d√° impress√£o que ela "criou" algo que n√£o existia, mas n√£o √© cria√ß√£o, √© aleatoriedade, pura sorte. √â a nuvem no c√©u. N√£o √© um processo repet√≠vel e ela n√£o sabe refletir algo como "uau, isso que eu inventei √© da hora, nunca tinha visto antes". Ela n√£o tem emo√ß√µes pra conseguir dizer "uau".</p>
<p>Se voc√™ der o c√≥digo de uma IA feita com RNNs como falei antes pro GPT 4 analizar, ela n√£o vai magicamente conseguir chegar no paper de transformers. Se esse paper n√£o estava no material de treinamento, ela n√£o vai concluir sozinha que esse era o pr√≥ximo passo. Portanto ela √© incapaz de conseguir chegar num GPT 5. Novas descobertas precisam ser feitas por humanos, documentadas, alimentadas no treinamento da IA e s√≥ a√≠ ela vai saber cuspir o texto desse paper. Ela √© incapaz de usar o que aprendeu pra gerar descobertas novas de forma intencional.&nbsp;</p>
<p>Existe uma historinha que √© chamado do Teorema dos Macacos Infinitos. O teorema sugere que se tivermos um macaco apertando teclas numa m√°quina de escrever por uma quantidade infinita de tempo, quase com certeza vai conseguir digitar qualquer tipo de texto, incluindo todas as obras do Shakespeare. Na pr√°tica, estamos falando de uma quantidade t√£o absurda de tempo que seria imposs√≠vel at√© de voc√™s terem no√ß√£o, estamos falando provavelmente de mais tempo que a idade atual do Universo desde o Big Bang. Mas √© um conceito que demonstra que sim, sem nenhuma intelig√™ncia, s√≥ com aleatoridade, dado um tempo absurdo, uma hora tudo que j√° produzimos vai aparecer.&nbsp;Sem nenhuma inten√ß√£o, s√≥ via aleatoriedade.</p>
<p>√â uma hist√≥ria pra dar no√ß√£o de conceitos como infinito e aleatoriedade. Essa hist√≥ria √© creditada ao matem√°tico franc√™s Felix √âmile Borel, de 1913. Ou seja, desde o come√ßo do s√©culo XX j√° se tinha essa no√ß√£o que muitos de voc√™s, mais de um s√©culo depois, ainda est√£o com dificuldades de entender. GPT e derivados s√£o macacos modernos dessa hist√≥ria. S√≥ que em vez de totalmente aleat√≥rio, demos um modelo de probabilidades pra facilitar o trabalho dele, s√≥ isso. Mas chamar de macaco √© meio ofensivo, pro coitado do macaco, que ainda √© mais inteligente que qualquer IA.&nbsp;</p>
<p>Falando em s√©culo passado. Deixa eu aproveitar pra voltar l√° atr√°s na hist√≥ria das intelig√™ncias artificiais. O estudo de algoritmos e t√©cnicas que contribuem pra esse campo existe desde os anos 50 pelo menos. Mas nos anos 70 surgiu um programa que at√© hoje ainda deixa os desavisados meio surpresos. O nome do programa √© Eliza. Existem v√°rias vers√µes, inclusive rodando online. D√™em uma olhada.</p>
<p>(... screencast eliza ...)</p>
<p>Como podem ver, √© um chatbot tamb√©m, que nem o ChatGPT. E parece uma pessoa bem desconfiada, fica dando umas respostas meio grossa. Weebs de anime chamariam ela de "tsudere". Mas se hoje povo fica empolgado com ChatGPT respondendo, imagina isso nos anos 70. S√≥ pra dar contexto, isso √© antes da revolu√ß√£o dos microcomputadores de 8-bits como Commodore ou Apple II. Isso √© antes da Microsoft ou Apple existirem. Nem internet existia ainda. Quando eu rodei uma vers√£o de Eliza pra DOS l√° no come√ßo dos anos 90, lembro que fiquei fascinado e pensando como eu faria a minha pr√≥pria vers√£o. E a√≠ voc√™s podem se perguntar, "caraca, mas como era poss√≠vel ter isso nessa √©poca??"</p>
<p>Bom, quem faz ci√™ncias da computa√ß√£o ou programa um pouco, j√° deve ter entendido o funcionamento. O modelo √© super simples. √â baseado inteiramente em pattern matching. Basicamente encontrar palavras-chave, ver se tem uma resposta pr√©-programada, e montar essa resposta, na m√£o. √â um sistema de templates. Quando eu digo "na m√£o", aqui sim, ao contr√°rio de modelos de transformers, √© realmente um monte de "ifs". Quem j√° montou agentes ou robozinhos, tanto de chat de suporte ou email marketing, j√° fez coisa similar pra respostas autom√°ticas. √â um bom exerc√≠cio de faculdade pra iniciantes.</p>
<p>No GitHub vai achar v√°rias vers√µes. Veja esta, √© uma vers√£o feita em Java. E vamos ver o tal "modelo" entre aspas. √â uma lista de chaves e valores, e os valores, como podem ver, s√£o frases pr√©-prontas. Por exemplo, se durante o chat voc√™ se desculpa e escreve algo como "I'm sorry", ele quebra essa string, encontra a palavra "sorry" e nesta lista olha s√≥, tem 3 respostas pr√©-programadas. Ela pode te responder "Por favor, n√£o se desculpe" ou "Desculpas n√£o s√£o necess√°rias". E vai escolher aleatoriamente, pra n√£o parecer que t√° se repetindo.</p>
<p>S√≥ isso j√° √© suficiente pra passar no Teste de Turing, que √© um teste feito pra identificar quando uma intelig√™ncia artificial consegue enganar um ser humano numa breve conversa. Eliza √© a av√≥ espiritual do ChatGPT. Mas o ponto em apresentar a Eliza √© pra voc√™s verem que pra enganar seres humanos, n√£o precisa muito. Por alguma raz√£o, n√≥s seres humanos, somos muito f√°ceis de enganar e somos propensos a acreditar em qualquer coisa. Acho que somos animais com f√© excessiva. √â um ponto forte, mas √© um enorme ponto fraco tamb√©m. Eu pessoalmente sou c√©tico, mas a√≠ me chamam de "do contra", vai entender. Vou continuar n√£o sendo o trouxa, s√≥ isso.</p>
<p>Um ChatGPT, se eu quisesse simplificar bastante, n√£o √© muito diferente da Eliza, em conceito. √â um programa que usa um modelo, um dicion√°rio de probabilidades, que mostra frases de acordo com o que se digitou antes, roboticamente, automaticamente, pegando palavras cujos valores de probabilidade fazem mais sentido dado as palavras anteriores. N√£o existe nenhuma emo√ß√£o envolvida. N√£o existe simpatia, n√£o existe compaix√£o, n√£o existe amargura. Nada. N√£o tem uma linha de c√≥digo, nem de dados no modelo, que representam qualquer emo√ß√£o. √â apenas uma calculadora, que em vez de devolver n√∫meros, devolve conjuntos de palavras. S√≥ isso.</p>
<p>Mas e as IAs que geram imagens in√©ditas? Vide o pr√≥prio Dall-e 2 da OpenAI, vide o Midjourney, vide o Stable Diffusion, vide os novos plugins de gera√ß√£o e ajustes de imagens propriet√°rio da Adobe, que come√ßaram a ser distribu√≠dos no Creative Cloud. Classifica√ß√£o de imagens e gera√ß√£o de novas imagens s√£o campos diferentes dentro de intelig√™ncia artificial. S√≥ pra n√£o perder o gancho, deixa eu jogar na mesa mais alguns conceitos.</p>
<p>Um campo que existe desde pelo menos os anos 80 √© o estudo sobre CNNs. (piada) N√£o, n√£o, n√£o √© esse, √© um CNN √∫til. Convolutional Neural Networks, que √© um modelo que dizem que √© bom pra processar dados que se parecem com grades, como uma grade de pixels, que √© como representamos uma imagem. As tais camadas convolucionais, n√£o sei se √© assim que fala em portugu√™s, aplicam v√°rios filtros ou kernels, aos dados de pixels pra criar um mapa de funcionalidades.&nbsp;</p>
<p>Em resumo, esses filtros extraem caracter√≠sticas da imagem. O equivalente a tokenizar um texto e gerar palavras ou n-grams. Mas CNNs ficaram super famosos s√≥ depois de 2012 quando saiu a AlexNet de Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton. (piada) Arregacei os nomes, mas beleza. Era um concurso que todo ano o vencedor ficava um pouco melhor do que o do ano anterior. Mas em 2012, o salto foi uma ordem de grandeza melhor. N√£o lembro os n√∫meros, mas faz de conta que todo ano os melhores algoritmos conseguiam identificar 85% das imagens, no ano seguinte, 86%, a√≠ do nada deu um salto pra 99%. Isso gerou um enorme interesse na comunidade de pesquisa em cima de classifica√ß√£o de imagens.</p>
<p>Em paralelo, em 2014 surgiu o conceito de GANs, Generative Adversarial Networks ou redes generativas advers√°rias, desenvolvido pelo Ian Goodfellow e seus colegas. Foi um avan√ßo no conceito de gera√ß√£o de imagens. De forma simplificada √© como se fossem duas IAs uma competindo com a outra. Um gerador cria imagens e um discriminador avalia. Por exemplo, digamos que quero gerar imagens de gatos, o gerador faz as imagens, e o discriminador tenta identificar se √© um gato mesmo. √â um sistema que acelera o processo de aprendizado por fornecer feedbacks mais r√°pidos do que um treinamento supervisionado por humanos.</p>
<p>CNNs e GANs eu mencionei mais pra voc√™s saberem alguns nomes importantes. Mas o Dall-e da OpenAI n√£o usa GANs, ele usa um derivado do modelo de transformers do GPT s√≥ que aplicado a imagens. Assim como gera√ß√£o de respostas de texto, onde ele vai prevendo uma palavras ap√≥s a outra, levando o contexto anterior em considera√ß√£o, o Dall-e tamb√©m usa uma arquitetura de transformers, criando imagens um peda√ßo atr√°s do outro. Ou seja, tamb√©m usa mecanismos de auto-aten√ß√£o em vez de camadas recorrentes ou convolucionais tradicionais.</p>
<p>Essa n√£o √© a √∫nica forma de se criar um gerador de imagens. Mais do que o Dall-e, que √© fechado, eu gosto mais do Stable Diffusion que, assim como o LLaMA da Meta, tamb√©m foi liberado publicamente como modelo aberto. Quem me acompanha no Instagram viu quando eu fiquei brincando de usar o Stable Diffusion com outras ferramentas abertas pra fazer remasteriza√ß√£o, upscaling de video. Assim eu pegava um video super antigo com qualidade de DVD e conseguia fazer ele redesenhar uma vers√£o 4K. Se n√£o viu isso, veja o destaque "Usando IA" no meu Insta. Enfim, diferente do Dall-e que usa transformers, o Stable Diffusion, como o pr√≥prio nome diz, usa um modelo de difus√£o.</p>
<p>Esse modelo gera imagens simulando um processo aleat√≥rio rodando em reverso, ou seja, o processo de gera√ß√£o come√ßa com uma simples distribui√ß√£o, como um Gaussian noise, literamente um gerador de barulho aleat√≥rio mesmo, e vai gradualmente refinando esse barulho, passo a passo, at√© chegar numa imagem que parece com os dados que o modelo foi treinado. √â meio como partir de um punhado de argila, tudo bagun√ßado, e passo a passo ir esculpindo e refinando, at√© chegar numa est√°tua. Esse processo de refinamento √© dirigido por uma rede neural que aprende a predizer o pr√≥ximo passo da difus√£o. E por isso se chama Stable Diffusion, ou Difus√£o Est√°vel.</p>
<p>Um site que parece que tem ganhado relev√¢ncia na comunidade de pesquisa e desenvolvimento de ferramentas e modelos de IA, √© o HuggingFace. Ele serve como um reposit√≥rio. √â de l√° que podemos baixar os modelos do LLaMA, Alpaca, Vicuna em todos os diferentes tamanhos e formatos. Existem modelos espec√≠ficos pra texto como o Vicuna, espec√≠fico pra imagens como o do Stable Diffusion, conversor de texto pra √°udio como o Speech T5 do Facebook e muitos outros. O ponto √© que n√£o existe uma √∫nica intelig√™ncia unificada que faz tudo, existem modelos isolados e independentes feitos pra tarefas espec√≠ficas. Um GPT n√£o sabe converter texto em √°udio, isso √© outro modelo.</p>
<p>Portanto, quando ver produtos web que parecem uma √∫nica intelig√™ncia, n√£o √©, √© um integrador que divide o que voc√™ pediu entre diversas intelig√™ncias diferentes. O que me leva a outro tema que queria tocar de leve, mesmo porque s√≥ comecei a estudar isso recentemente. Eu expliquei como as coisas funcionam, superficialmente, por baixo dos panos. Mas agora precisamos falar do que fica por cima dos panos, o que usu√°rios normais como eu e voc√™ enxergam, a interface.</p>
<p>N√£o s√≥ interface gr√°fica web de chat, mas interface de APIs e tudo mais. Surgiu um framework que tem ganhado cada vez mais relev√¢ncia na comunidade que est√° investindo pra construir ferramentas integradas com os diversos servi√ßos de IA que mencionei, como GPT, Bard, Stable Diffusion e outros. Esse framework se chama LangChain. A grosso modo, pense um framework como Django, ou Laravel, ou Rails, ou Spring, mas feito pra construir aplicativos que usam IA.</p>
<p>Eu gostei particularmente da documenta√ß√£o. Pra um projeto de c√≥digo aberto novo, tem material suficiente de estudo, incluindo pesquisa de papers acad√™micos sendo publicados agora. Em particular queria tocar no ponto de prompts. A moda dos parasitas sangue-suga agora, √© criar cursos online de prompts. J√° viram por a√≠? "Vire um Engenheiro de Prompt". √â a coisa mais idiota que j√° vi.</p>
<p>Seria o equivalente a voc√™ se chamar de "Engenheiro de Pesquisa no Google". J√° deixo a dica pra voc√™: n√£o fa√ßa nenhum deles. Sem nem olhar, posso garantir que quase todos s√£o pega-trouxa. Lembra aquele ditado? Todo dia um malandro e um ot√°rio acordam e v√£o pra rua, e quando se encontram, rola neg√≥cio. N√£o seja o ot√°rio.</p>
<p>Enfim, o LangChain √© um framework extenso. N√£o pense algo simples como um Express de Node.js. Isso t√° mais pra um Spring de Java. Tem diversos conceitos, como Models pra interfacear com os diversos servi√ßos de IA, como o ChatGPT. A grosso modo esses Models seriam como um Hibernate, um ORM pra IAs. Mas tem outras abstra√ß√µes. Tem Agentes. Tem Correntes. Tem √çndices, mas uma das partes interessantes √© que tem Prompts.</p>
<p>Diferente desses cursinhos idiotas por a√≠, que ficam mais no esquema "olha s√≥, eu testei uns prompts aqui e vou compartilhar com voc√™s" ou ent√£o povo que fica copiando teorias da conspira√ß√£o de prompt que surgem no Reddit. De fato existem pesquisas acad√™micas sendo feitas no estudo das melhores formas de se fazer perguntas pra passar pra um transformador generativo como GPT. Lembram o que eu falei? Os transformers s√≥ continuam adicionando palavras na frente do prompt que voc√™ escreveu. Quanto melhor escrito for o prompt, maiores as probabilidades de se conseguir as respostas que procura. Ele vai conseguir prever melhor as palavras seguintes.</p>
<p>O melhor prompt n√£o √© escrever um text√£o aleat√≥rio, mas sim conciso e estruturado. Na documenta√ß√£o eles fazem links pros diversos papers acad√™micos com o estudo pra cada t√≥pico. Eu n√£o levaria 100% a s√©rio, nem todos os papers s√£o consenso, muita coisa √© s√≥ teoremas e hip√≥teses. Mas √© melhor do que chutes do YouTuber.</p>
<p>Com um LangChain, eu poderia fazer um Model que se integra com o meu Vicuna rodando localmente, da√≠ poderia n√£o depender de servi√ßos de terceiros e tamb√©m manter a privacidade dos meus dados, j√° que n√£o preciso compartilhar nada com ningu√©m. Se algu√©m tiver interesse de estudar, pesquisar ou at√© empreender com essa nova gera√ß√£o de transformadores, essas s√£o ferramentas que podem ser muito √∫teis. Esquece curso idiota que √© "duh, olha s√≥ como sou inteligente, sei integrar com a API da OpenAI". S√©rio, isso √© o b√°sico do b√°sico do b√°sico, voc√™ aprende em 10 minutos num blog post. N√£o tem absolutamente nada demais.&nbsp;</p>
<p>Ali√°s, um curso de IA que se preza, tem por obriga√ß√£o ter tudo que eu falei neste v√≠deo, s√≥ que explicado com 10 vezes mais detalhes. Caso contr√°rio n√£o vale seu dinheiro e muito menos seu tempo. N√£o perca tempo com esses cursos ca√ßa n√≠quel. S√£o todos perda de tempo. Veja os links que deixei na descri√ß√£o do video e estude um a um que no final voc√™ vai aprender muito melhor, e de gra√ßa. O hype em torno de IA est√° fora de propor√ß√£o. Um prato cheio pros oportunistas de plant√£o.</p>
<p>Pra finalizar, acho que vale a pena voltar na quest√£o que incomoda todo programador iniciante: "mas ser√° que com essa evolu√ß√£o r√°pida de transformers, n√£o √© quest√£o de tempo at√© ele substituir todos os programadores?". Eu j√° tinha feito um video s√≥ pra responder isso e recomendo que assistam, mas considerando o que expliquei hoje, vou explicar porque, tecnicamente, isso n√£o vai acontecer.</p>
<p>Primeiro. Um transformer √© incapaz de gerar textos sobre assuntos que nunca viu na vida. Isso √© importante de entender. Vamos recordar, o que √© um modelo, √© um banco de dados de tokens retirados dos textos de treinamento e mais importante: as probabilidades de um token pra outro token dentro de uma rede. O modelo n√£o cont√©m o texto original, s√≥ pesos.</p>
<p>Vou repetir porque isso √© importante: nenhum texto original aparece na sua forma original, dentro do modelo. Pra ter na cabe√ßa pense assim. J√° viram que v√°rios livros no final tem algumas p√°ginas com um "√≠ndice remissivo"? S√£o todas as palavras importantes que aparecem no texto do livro e as p√°ginas onde aparecem. √â que nem um √≠ndice rudimentar de banco de dados.</p>
<p>Quando fazemos um prompt e pedimos, sei l√°, pra ele citar um trecho da pe√ßa King Lear, de Shakespeare. Vai gerar o trecho, se n√£o igual, muito pr√≥ximo ao trecho do texto original. E isso confunde, pois parece que ent√£o, ele tem o texto inteiro guardado em algum lugar. Mas n√£o. Por exemplo, pedi pra ele citar um di√°logo entre Albany e Cordelia e corretamente diz que n√£o existe di√°logo entre os dois na pe√ßa, e sugere outra cena, Ato 4, Cena 2, onde Albany fala com sua esposa Goneril. E segue o trecho exatamente como est√° na pe√ßa.&nbsp;</p>
<p>Novamente, √© muito dif√≠cil tra√ßar o caminho exato dentro do modelo, indo de probabilidade em probabilidade pra reverter o processo e descobrir como o GPT conseguiu escrever o texto. Mas podemos dar um chute educado: a sequ√™ncia de palavras do di√°logo tem alt√≠ssima probabilidade. Primeiro, no meu prompt tem todas as palavras-chave importantes pro contexto como "Shakespeare", "Albany" e tudo mais.</p>
<p>Quando ele come√ßa digitando o trecho "You are" no contexto to di√°logo, a chance maior √© da pr√≥xima palavra ser "not", depois da palavra ser "worth", depois ser "the" e depois "dust". S√£o as probabilidades mais altas dessa sequ√™ncia. Ele n√£o tem o texto original, mas tem as probabilidades, que permitem remontar uma boa parte do texto original.</p>
<p>At√© certo ponto, a grosso modo, o modelo acaba servindo como uma vers√£o comprimida dos textos originais, mas com perdas. Quebramos todos os textos em tokens e gravamos os relacionamentos de forma que √© poss√≠vel recuperar alguns desses textos. Mas n√£o podemos garantir que √© poss√≠vel recuperar tudo, porque a mistura de alguns textos similares vai desajustar as probabilidades.</p>
<p>No final ter√≠amos no m√°ximo uma vers√£o mesclada de dois ou mais textos. Quanto mais repetidas vezes um determinado texto aparece em diversas fontes no material de treinamento, maiores as chances de conseguir reconstruir depois. Shakespeare, tendo obras que foram analisadas, discutidas e citadas in√∫meras vezes em v√°rias fontes, tem maiores chances de ser reconstru√≠do.&nbsp;&nbsp;</p>
<p>Sobre mim, Fabio Akita, j√° vai ser mais dif√≠cil, porque no contexto geral da Web, eu sou extremamente pouco citado. Mesmo assim, o GPT 4 at√© que consegue fazer uma descri√ß√£o super gen√©rica sobre mim. Fala coisas certas, por exemplo, que sou brasileiro, que fundei a CodeMiner, que palestrei em eventos e ajudei a divulgar Ruby on Rails. Mas a√≠ fala que tamb√©m ajudei a divulgar metodologias √Ågeis, que n√£o √© mentira, mas nunca foi um ponto importante.</p>
<p>Ele fala que fui "keynote speaker", ou seja, que dei palestra de abertura em muitas confer√™ncias, o que n√£o √© verdade. Ele j√° come√ßou a misturar informa√ß√µes de outras pessoas similares. Mas isso n√£o √© acidente, √© porque comparado a um Shakespeare, n√£o tem quase nada sobre mim na Web, e as probabilidades s√£o muito parecidas com outros palestrantes de tecnologia da mesma √°rea.</p>
<p>Por isso tamb√©m √© dif√≠cil pra ele citar fontes exatas, porque cada palavra do texto que gera pode ter vindo de um lugar diferente. N√£o tem como saber exatamente. Pra ter links pra fontes, como o Bing faz, especulo que precisa de um processo em duas ou mais etapas. Primeiro, gerar o texto da resposta, como um GPT faz. Depois, pegar esse texto e fazer uma pesquisa tradicional no Bing antigo. Da√≠ cruzar as duas informa√ß√µes e ver se os textos minimamente batem, e finalmente apresentar juntas, como se a resposta j√° tivesse sa√≠do pronto com os links pras fontes.&nbsp;</p>
<p>N√£o √© o transformer que d√° os links, √© um segundo processo separado. Porque o modelo do transformer, em si, n√£o tem como garantir exatamente qual parte veio de onde. Quanto mais um certo assunto tiver textos pra treinar, mais precisas v√£o ser as respostas. Por isso √© mais f√°cil conseguir informa√ß√µes sobre celebridades, do que sobre algu√©m como eu ou voc√™s. No nosso caso, nossas informa√ß√µes v√£o ser misturadas com de outras pessoas similares, porque as probabilidades n√£o v√£o ajudar.&nbsp;</p>
<p>Lembra a temperatura de "criatividade"? Ela garante que, mesmo sem saber a resposta exata, o ChatGPT vai continuar tentando responder baseado nas probabilidades que tem no modelo atual. Mas n√£o tem jeito, toda resposta sobre coisas que n√£o tinha no material original de treinamento, ou tinha muito pouco, vai ser uma alucina√ß√£o probabil√≠stica. S√≥ isso. E vai estar errado. E isso vai acontecer com tudo que for novidade. No dia 1, todo transformer vai ser praticamente in√∫til.</p>
<p>Outra coisa, mesmo sendo capaz de ler c√≥digo, explicar c√≥digo dos outros e gerar c√≥digos, ainda n√£o vai ter a capacidade de gerar um projeto inteiro. Lembra os c√≥digos vazados do Twitch ou o c√≥digo de ranking do Twitter que eu analisei? Estamos falando de milhares de arquivos, centenas de milhares de linhas de c√≥digo. Sabe qual √© um dos calcanhares de aquiles de toda IA? Backtracking e mem√≥ria. As respostas costumam ser boa hoje porque ele leva em considera√ß√£o o texto anterior. Em partes.</p>
<p>Existe um limite de quanto consegue voltar atr√°s no texto anterior. No caso do GPT 3 e 4 atual, ele se limita a enxergar uma janela de contexto de no m√°ximo 2048 tokens. E as respostas tamb√©m tem um limite. Quanto mais longo for esse limite, mais caro fica pra processar o resultado seguinte do gerador de palavras, maiores as chances dele come√ßar a "esquecer" o contexto e muito maiores as chances de rapidamente perder a coer√™ncia de respostas longas.</p>
<p>Entendam: o GPT atual n√£o tem capacidade de ler mais que 2048 tokens. Ent√£o jogar o c√≥digo inteiro da kernel do Linux pra ele analisar, por exemplo, √© imposs√≠vel. E pedir pra ele escrever um c√≥digo desse mesmo tamanho, √© mais imposs√≠vel ainda. L√≥gico, nada √© imposs√≠vel, mas √© altamente improv√°vel. No meu Vicuna rodando local, tem essa tela de configura√ß√£o pra justamente configurar o tamanho da janela de contexto e de resposta. E n√£o √© um n√∫mero muito grande n√£o,</p>
<p>Num teste n√£o cient√≠fico, tentei abrir duas janelas do projeto text-generation que √© a interface web que estou usando em cima do Vicuna. N√£o sei se √© uma precau√ß√£o da interface web ou uma limita√ß√£o do pr√≥prio Vicuna por baixo, mas s√≥ tem capacidade de responder uma pergunta de cada vez. Se eu abrir outro navegador e tentar fazer outra pergunta, enquanto na outra janela ele ainda n√£o terminou de responder a primeira, vai ignorar e n√£o deixa rodar em paralelo.</p>
<p>E mesmo se conseguisse. S√≥ com um √∫nico processo de resposta, est√° consumindo, no m√≠nimo, 50% da minha GPU, consumindo mais de 18 gigabytes de VRAM, e enquanto responde esse consumo continua aumentando. Ou seja, numa m√°quina como a minha, ele s√≥ consegue responder uma pergunta de cada vez. Voc√™ est√° pensando em fazer um servi√ßo online, SaaS, pra v√°rios usu√°rios acessarem? Vai sair super caro, porque s√≥ vai possibilitar uma resposta a cada 2 a 5 segundos. Um servidor web pequeno tem capacidade pra responder, sei l√°, 1000 requisi√ß√µes por segundo ou mais. Mas um Vicuna est√° mais pra 0.2 requisi√ß√µes por segundo. √â ridiculamente pesado e n√£o escala.</p>
<p>N√£o lembro que artigo que a OpenAi falava que cada dia de opera√ß√£o do ChatGPT custa 1 milh√£o de d√≥lares. Sim, 1 milh√£o, por dia. Mais ou menos faz sentido, dado o custo de GPU necess√°rio pra responder todo mundo. Mas claro, novas t√©cnicas de otimiza√ß√£o tem aparecido, como o exemplo de quantiza√ß√£o que expliquei antes, mas estamos falando que precisa melhorar ainda umas 10 mil vezes pra ficar economicamente vi√°vel pra casos como escrever um livro inteiro de 500 p√°ginas, sem perder coer√™ncia, ou escrever um projeto de verdade com milhares de arquivos de c√≥digo. No est√°gio atual da tecnologia, isso √© imposs√≠vel.</p>
<p>Essas s√£o s√≥ algumas das raz√µes de porque um ChatGPT n√£o vai substituir programadores e outras profiss√µes. A partir de um certo ponto fica t√£o caro que n√£o compensa, especialmente porque como j√° expliquei, essa ¬®intelig√™ncia" n√£o √© inteligente, s√≥ cospe probabilidades. N√£o tem criatividade, n√£o sabe tomar decis√µes baseadas em coisas como custo-benef√≠cio ou bom senso. N√£o vai ter coer√™ncia em respostas longas, n√£o tem no√ß√£o se o c√≥digo sendo cuspido tem seguran√ßa, ou escalabilidade. Ela tem mem√≥ria menor que um peixinho dourado. 2048 tokens. Mesmo se aumentar 10x esse limite, ainda √© super pouco.&nbsp;O script deste epis√≥dio tem 15 mil palavras. O ChatGPT √© incapaz de escrever meus scripts.</p>
<p>Mas tudo bem, como uma ferramenta de aux√≠lio, √© super boa. Trechos pequenos e repetitivos, ou c√≥digo trivial que facilmente encontramos num stackoverflow repetidas vezes. O estado atual de transformers √© mais que suficiente pra acelerar um bom profissional. Hoje √© imposs√≠vel e vai continuar sendo imposs√≠vel algu√©m que n√£o √© programador conseguir fazer um projeto complexo inteiro. Qualquer um que diga o contr√°rio n√£o tem a menor no√ß√£o do que est√° falando. Considere como os algoritmos funcionam e considere os pontos de m√°ximo e m√≠nimo. N√£o basta dizer "ah, eu tenho esperan√ßa, √© s√≥ ter f√©". Precisamos de n√∫meros e os n√∫meros dizem que √© extremamente improv√°vel.</p>
<p>Eu uso o GitHub Copilot faz meses. Em v√°rios videos, toda vez que aparece trechos de c√≥digo, usei a ajuda do ChatGPT ou Copilot. Ambos tem plugins pra v√°rios editores como NeoVim ou VS Code e funcionam super bem. Tem capacidade de ler o c√≥digo do arquivo que se est√° editando. N√£o consegue usar o projeto inteiro de contexto pelos limites que acabei de explicar, mas s√≥ de usar o trecho pr√≥ximo do que est√° digitando, j√° ajuda muito. Ou seja, parte do prompt √© o c√≥digo do arquivo aberto naquele momento.&nbsp;</p>
<p>Pra mim, vale cada centavo. E todo desenvolvedor que quiser ter vantagens de produtividade, deveria considerar usar esses plugins. De novo, n√£o vai conseguir fazer tudo pra voc√™, e por causa da aleatoriedade e alto risco de alucina√ß√µes, voc√™ nunca deve aceitar o c√≥digo que ele sugere sem ler com muita calma antes. Mas pra tarefas bem bra√ßais, tediosas, onde far√≠amos muito copy e paste, como fazer testes unit√°rios simples, ajuda. Testem.</p>
<p>Com tudo isso que expliquei, minha conclus√£o pessoal √© que n√£o estamos nada perto do que o povo chama de AGI, ou Intelig√™ncia Artificial Geral. A IA que vai superar todas as IAs. A IA que vai pegar o c√≥digo inteiro do GPT 4 e sozinho gerar um GPT 5 melhorado. O coitado male male tem capacidade de lembrar de um √∫nico arquivo de c√≥digo, que dir√° milhares. Mesmo se conseguisse, ele n√£o estar√° "analisando". Ele n√£o analisa nada. Ele n√£o sabe analisar. N√£o sabe as regras de c√°lculo, as regras de programa√ß√£o. S√≥ sabe juntar peda√ßos que viu repetidas vezes de muitas fontes, 100% via probabilidades. Quando n√£o sabe, vai pegar as probabilidades mais pr√≥ximas e cuspir o que der, e vai ser um texto sem sentido nenhum.</p>
<p>Vou repetir: transformers n√£o tem intelig√™ncia nenhuma de an√°lise e cogni√ß√£o. Ele n√£o sabe porque 2 mais 2 √© 4, s√≥ leu muitas vezes que √©, e as probabilidades fazem ele repetir isso. GPT quer dizer Transformer Generativo Pr√©-Treinado. Hoje voc√™ entendeu o que esses termos significam. E se ficou at√© aqui, espero que tenha entendido: por mais impressionante que pare√ßam os textos que gera, √© s√≥ um gerador de textos, um auto-corretor de teclado de celular glorificado.</p>
<p>Um gerador de textos nunca vai ser inteligente. S√≥ vai "parecer" inteligente. Assim como o formato de animal que voc√™ viu numa nuvem foi totalmente um acidente. Ningu√©m teve a inten√ß√£o de desenhar um animal na nuvem, sequer √© um animal, √© s√≥ um formato aleat√≥rio. Foi voc√™ que escolheu entender assim.&nbsp;</p>
<p>E foi por isso que no outro epis√≥dio de ChatGPT eu afirmei e repito: Seu grau de empolga√ß√£o com IA √© inversamente proporcional ao seu entendimento de IA. Quanto menos entender, mais empolgado vai ficar. Vai acreditar que as a√ß√µes da NVIDIA estarem a mais de 400 d√≥lares √© normal, porque acredita que neg√≥cios de IA v√£o aumentar absurdamente e em breve a a√ß√£o vai atingir 1000 d√≥lares. Vai investir todo seu dinheiro nisso. J√° eu, acho que a a√ß√£o da NVIDIA est√° hiper valorizado por puro hype. O pre√ßo justo da a√ß√£o deveria ser abaixo de 300 d√≥lares, e vai voltar pra isso uma hora. N√£o sei quando vai estourar, mas eu estou precavido.</p>
<p>N√£o tenho d√∫vidas que transformers s√£o √∫teis. V√°rias ferramentas j√° est√£o usando. Em particular o Creative Cloud da Adobe t√° tirando bom proveito. A Microsoft vai embutir em Office, Windows e tudo mais. Mas no final √© isso que vamos ter: um Alexa melhorado. Um template mais inteligente de Excel. Mas n√£o ache que vai substituir seu Diretor Financeiro e que ele vai conseguir tomar decis√µes inteligentes. S√≥ parece, por sorte e por acidente. Quem apostar em mais do que isso, nas tecnologias atuais, vai perder.</p>
<p>Pessoalmente eu acho que as tecnologias de transformers e outras que nem mencionei hoje que comp√µe o que √© o GPT, assim como tudo, segue uma curva em S. Passamos pela parte do S que √© o crescimento que parece exponencial, mas a curva tem um teto em cima. Quando pulamos de bilh√µes de par√¢metros pra trilh√µes de par√¢metros, vamos come√ßar a ter retornos diminu√≠dos, diminishing returns. Se amanh√£ sair um GPT 5 com o dobro de par√¢metros, sei l√° 300 trilh√µes, n√£o vai ficar duas vezes melhor. Talvez melhore sei l√°, 20%. Cada melhoria custa mais caro do que o retorno. Isso √© diminishing returns.&nbsp;</p>
<p>N√£o existe crescimento infinito, e quanto mais r√°pido voc√™ for√ßa, s√≥ chega mais r√°pido no teto. Precisa acontecer novas descobertas, novas inven√ß√µes que ainda n√£o conhecemos, obviamente, pra ter uma nova etapa de evolu√ß√£o significativa. Enquanto isso n√£o acontecer e s√≥ insistir no que temos at√© hoje, n√£o vai ser muito melhor que isso n√£o. J√° estamos perto do limite. E AGI n√£o est√° no horizonte ainda. √â a mesma coisa ficar especulando se estamos pertos de conseguir construir uma USS Enterprise. √â irrelevante, beira fic√ß√£o cient√≠fica.</p>
<p>Acho que j√° me estendi demais. Como falei no come√ßo do video, eu n√£o sou nem de longe um especialista no assunto, sequer tenho experi√™ncia pr√°tica de trabalhar em projetos relacionados. Meu conhecimento at√© agora √© puramente te√≥ricos. Eu s√≥ pesquisei o que existe publicado online. Se eu entendi at√© aqui em poucos dias, quem dedicar algumas semanas vai acabar sabendo muito mais do que eu, muito rapidamente. N√£o √© t√£o dif√≠cil assim. Espero que tenha dado pra quebrar alguns mitos que tinham na cabe√ßa e finalmente tenham conseguido separar o joio do trigo. Se ficaram com d√∫vida ou quiserem complementar, fiquem a vontade nos coment√°rios abaixo. Se curtiram o video deixem um joinha, assinem o canal e n√£o deixem de compartilhar o video com seus amigos. A gente se v√™, at√© mais.</p>
<p></p>